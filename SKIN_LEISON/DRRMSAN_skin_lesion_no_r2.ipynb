{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DRRMSAN_skin_lesion_no_r2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWRNrTnsIiMj",
        "outputId": "77fdb1a5-788c-4538-ca27-a7a5906018bb"
      },
      "source": [
        "!gdown https://drive.google.com/u/0/uc?id=1-OdmzC3JvmUsZUMrNAKPnu8ZM7EeSK04"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1-OdmzC3JvmUsZUMrNAKPnu8ZM7EeSK04\n",
            "To: /content/skin_lesion.zip\n",
            "50.2MB [00:00, 88.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMYUxGyUIztr"
      },
      "source": [
        "! unzip -qq skin_lesion.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P37zyLtII1oo",
        "outputId": "246b60f7-2066-4d51-a436-bb5c2542551d"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbsulRzWI3xY"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization\n",
        "from tensorflow.keras.layers import UpSampling2D, Input, Concatenate\n",
        "from tensorflow.keras.models import Model , load_model\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.metrics import Recall, Precision \n",
        "from tensorflow.keras import backend as K\n",
        "#from models import DRRMSAN_multiscale_attention\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dskVOp1uI6AP"
      },
      "source": [
        "PATH = \"\"\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "## Hyperparameters\n",
        "\n",
        "#IMG_SIZE = 256\n",
        "EPOCHS = 20\n",
        "BATCH = 2\n",
        "LR = 1e-5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxaY9U4MJBV5"
      },
      "source": [
        "def load_data(path, split=0.2):\n",
        "  \"\"\"\n",
        "  from glob import glob\n",
        "  images_list = sorted(glob(os.path.join(path, \"trainx/*.bmp\")))\n",
        "  masks_list = sorted(glob(os.path.join(path, \"trainy/*.bmp\")))\n",
        "  \"\"\"\n",
        "\n",
        "  import sys\n",
        "  import glob\n",
        "  from tqdm import tqdm\n",
        "  #insert :: sys.path.insert(0, '../../')\n",
        "  \n",
        "  ############################## insert:: add ../ before two\n",
        "  img_files = glob.glob('trainx/*.bmp')\n",
        "  msk_files = glob.glob('trainy/*.bmp')\n",
        "\n",
        "  images_list = []\n",
        "  masks_list = []\n",
        "\n",
        "\n",
        "  for img_fl in tqdm(img_files):\n",
        "    if(img_fl.split('.')[-1]=='bmp'):\n",
        "      images_list.append(img_fl)\n",
        "      # insert :: img_msk = \"../trainy/Y_img_\"+str(img_fl.split('.')[2]).split('_')[-1]+\".bmp\"\n",
        "      img_msk = \"trainy/Y_img_\"+str(img_fl.split('.')[0]).split('_')[-1]+\".bmp\"\n",
        "      #print(\"----\",img_msk)\n",
        "      #break\n",
        "      masks_list.append(img_msk)\n",
        "  \n",
        "  \n",
        "  tot_size = len(images_list)\n",
        "  test_size = int(split * tot_size)\n",
        "  val_size = int(split * (tot_size - test_size))\n",
        "\n",
        "  x_train, x_val = train_test_split(images_list, test_size=val_size, random_state=42)\n",
        "  y_train, y_val = train_test_split(masks_list, test_size=val_size, random_state=42)\n",
        "\n",
        "  x_train, x_test = train_test_split(x_train, test_size=test_size, random_state=42)\n",
        "  y_train, y_test = train_test_split(y_train, test_size=test_size, random_state=42)\n",
        "\n",
        "  return (x_train, y_train), (x_val, y_val), (x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6-XnZe3JBTG"
      },
      "source": [
        "def read_img(path):\n",
        "    path = path.decode()\n",
        "    tmp = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    tmp = cv2.resize(tmp, (256, 192))\n",
        "    tmp = tmp/255.0\n",
        "    return tmp\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    tmp = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    tmp = cv2.resize(tmp, (256, 192))\n",
        "    tmp = tmp/255.0\n",
        "    tmp = np.expand_dims(tmp, axis=-1)\n",
        "    return tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "299t88LuJBP7"
      },
      "source": [
        "def tf_parse(a, b):\n",
        "    def _parse(a, b):\n",
        "        a = read_img(a)\n",
        "        b = read_mask(b)\n",
        "        return a, b\n",
        "\n",
        "    a, b = tf.numpy_function(_parse, [a, b], [tf.float64, tf.float64])\n",
        "    a.set_shape([192, 256, 3])\n",
        "    b.set_shape([192, 256, 1])\n",
        "    return a, b\n",
        "\n",
        "def tf_dataset(a, b, batch=32):\n",
        "    data = tf.data.Dataset.from_tensor_slices((a, b))\n",
        "    data = data.map(tf_parse)\n",
        "    data = data.batch(batch)\n",
        "    data = data.repeat()\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EqzP1t_JBM7",
        "outputId": "3a88ebd1-5230-42c8-929b-5c4d2212114b"
      },
      "source": [
        "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_data(PATH)\n",
        "\n",
        "print(\"Training data: \", len(x_train))\n",
        "print(\"Validation data: \", len(x_val))\n",
        "print(\"Testing data: \", len(x_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:00<00:00, 159661.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training data:  128\n",
            "Validation data:  32\n",
            "Testing data:  40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWu4fUh0JBHq"
      },
      "source": [
        "def read_and_rgb(a):\n",
        "    a = cv2.imread(a)\n",
        "    a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
        "    return a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1p4h33UJBEu"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# encoding: utf-8\n",
        "# @Time    : 01/12/2020 15:56\n",
        "# @Author  : Jimut Bahan Pal\n",
        "# DRRMSAN version with multi scaled alpha values\n",
        "\n",
        "from tqdm import tqdm\n",
        "from keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add\n",
        "from keras.models import Model, model_from_json\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras import backend as K \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.metrics import Recall, Precision \n",
        "\n",
        "\n",
        "# https://stackoverflow.com/questions/55809286/how-to-create-a-custom-keras-layer-min-pooling-but-ignore-zeros\n",
        "# Minpool2D implementation\n",
        "\n",
        "def MinPooling2D(x, pool_size, strides):\n",
        "\n",
        "    max_val = K.max(x) + 1 # we gonna replace all zeros with that value\n",
        "    # replace all 0s with very high numbers\n",
        "    is_zero = max_val * K.cast(K.equal(x,0), dtype=K.floatx())\n",
        "    x = is_zero + x\n",
        "\n",
        "    # execute pooling with 0s being replaced by a high number\n",
        "    min_x = -K.pool2d(-x, pool_size=(2, 2), strides=(2, 2))\n",
        "\n",
        "    # depending on the value we either substract the zero replacement or not\n",
        "    is_result_zero = max_val * K.cast(K.equal(min_x, max_val), dtype=K.floatx()) \n",
        "    min_x = min_x - is_result_zero\n",
        "\n",
        "    return min_x # concatenate on channel\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##=================================================\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Reshape, Permute, Activation, Input, \\\n",
        "    add, multiply, AveragePooling2D, SpatialDropout2D, Subtract, average\n",
        "from tensorflow.keras import initializers\n",
        "##=================================================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
        "    '''\n",
        "    2D Convolutional layers\n",
        "\n",
        "    Arguments:\n",
        "        x {keras layer} -- input layer\n",
        "        filters {int} -- number of filters\n",
        "        num_row {int} -- number of rows in filters\n",
        "        num_col {int} -- number of columns in filters\n",
        "\n",
        "    Keyword Arguments:\n",
        "        padding {str} -- mode of padding (default: {'same'})\n",
        "        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n",
        "        activation {str} -- activation function (default: {'relu'})\n",
        "        name {str} -- name of the layer (default: {None})\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
        "    x = BatchNormalization(axis=3, scale=False)(x)\n",
        "\n",
        "    if(activation == None):\n",
        "        return x\n",
        "\n",
        "    x = Activation(activation, name=name)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
        "    '''\n",
        "    2D Transposed Convolutional layers\n",
        "\n",
        "    Arguments:\n",
        "        x {keras layer} -- input layer\n",
        "        filters {int} -- number of filters\n",
        "        num_row {int} -- number of rows in filters\n",
        "        num_col {int} -- number of columns in filters\n",
        "\n",
        "    Keyword Arguments:\n",
        "        padding {str} -- mode of padding (default: {'same'})\n",
        "        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n",
        "        name {str} -- name of the layer (default: {None})\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
        "    x = BatchNormalization(axis=3, scale=False)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def MultiResBlock(U, inp, alpha = 1.67):\n",
        "    '''\n",
        "    MultiRes Block\n",
        "\n",
        "    Arguments:\n",
        "        U {int} -- Number of filters in a corrsponding UNet stage\n",
        "        inp {keras layer} -- input layer\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    W = alpha * U\n",
        "\n",
        "    shortcut = inp\n",
        "\n",
        "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
        "                         int(W*0.5), 1, 1, activation=None, padding='same')\n",
        "\n",
        "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    out = add([shortcut, out])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def attention_up_and_concate(down_layer, layer, filters):\n",
        "    '''\n",
        "    Attention up and concatenate layer\n",
        "\n",
        "    Arguments:\n",
        "        down_layer {keras layer} -- layer coming from the down\n",
        "        layer {keras layer} -- layer coming from the top\n",
        "        filters {int} -- number of channels in image\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "    \n",
        "    # up = Conv2DTranspose(out_channel, [3,  3], strides=[3,  3])(down_layer)\n",
        "    #up = UpSampling2D(size=(2, 2))(down_layer)\n",
        "\n",
        "    layer = proposed_attention_block_2d(down_layer, layer, filters)\n",
        "\n",
        "    # if data_format == 'channels_first':\n",
        "    #     my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n",
        "    # else:\n",
        "    #     my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
        "\n",
        "    #concate = my_concat([down_layer, layer])\n",
        "    return layer\n",
        "\n",
        "\n",
        "\n",
        "def attention_block_2d(ms_conv, res_block, filters):\n",
        "    '''\n",
        "    Attention block\n",
        "\n",
        "    Arguments:\n",
        "        ms_conv {keras layer} -- layer coming from the multi resolution convolution\n",
        "        res_block {keras layer} -- layer coming from the residual block\n",
        "        filters {int} -- number of channels in image\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    # theta_x(?,g_height,g_width,filters)\n",
        "    theta_x = Conv2D(filters, [1, 1], strides=[1, 1])(ms_conv)\n",
        "\n",
        "    # phi_g(?,g_height,g_width,filters)\n",
        "    phi_g = Conv2D(filters, [1, 1], strides=[1, 1])(res_block)\n",
        "\n",
        "    # f(?,g_height,g_width,filters)\n",
        "    f = Activation('relu')(add([theta_x, phi_g]))\n",
        "\n",
        "    # psi_f(?,g_height,g_width,1)\n",
        "    psi_f = Conv2D(1, [1, 1], strides=[1, 1])(f)\n",
        "    rate = Activation('sigmoid')(psi_f)\n",
        "\n",
        "    # rate(?,x_height,x_width)\n",
        "    # att_x(?,x_height,x_width,x_channel)\n",
        "    att_x = multiply([ms_conv, rate])\n",
        "\n",
        "    return att_x\n",
        "\n",
        "\n",
        "\n",
        "def proposed_attention_block_2d(ms_conv, res_block, filters):\n",
        "    '''\n",
        "    Proposed Attention block\n",
        "\n",
        "    Arguments:\n",
        "        ms_conv {keras layer} -- layer coming from the multi resolution convolution\n",
        "        res_block {keras layer} -- layer coming from the residual block\n",
        "        filters {int} -- number of channels in image\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    theta_x = Conv2D(filters, [1,  1], strides=[1, 1], padding='same')(ms_conv)\n",
        "    joint_conv_2x2 = Conv2D(filters, (2, 2), strides=(1, 1), padding='same', kernel_initializer = 'he_normal', kernel_regularizer=l2(1e-4))(theta_x)\n",
        "    conv_3x3 = SpatialDropout2D(0.5)(Activation('relu')(Conv2D(filters, (3, 3), strides=(1, 1), padding='same', kernel_initializer = 'he_normal', kernel_regularizer=l2(1e-4))(joint_conv_2x2)))\n",
        "    conv_5x5 = SpatialDropout2D(0.5)(Activation('relu')(Conv2D(filters, (5, 5), strides=(1, 1), padding='same', kernel_initializer = 'he_normal', kernel_regularizer=l2(1e-4))(joint_conv_2x2)))\n",
        "    conv_7x7 = SpatialDropout2D(0.5)(Activation('relu')(Conv2D(filters, (7, 7), strides=(1, 1), padding='same', kernel_initializer = 'he_normal', kernel_regularizer=l2(1e-4))(joint_conv_2x2)))\n",
        "    add_3x3_5x5 = add([conv_3x3, conv_5x5])\n",
        "    mult_3x3_5x5 = multiply([conv_3x3, conv_5x5]) #multiply([conv_3x3, conv_5x5])#Subtract()([conv_3x3, conv_5x5])\n",
        "    add_3x3_5x5_7x7 = Activation('sigmoid')(add([add_3x3_5x5, conv_7x7]))\n",
        "    mul_3x3_5x5_7x7 = Activation('sigmoid')(multiply([mult_3x3_5x5, conv_7x7]))#multiply([mult_3x3_5x5, conv_7x7]))) # Subtract()([mult_3x3_5x5, conv_7x7])\n",
        "    add_1x1_upper = Activation('sigmoid')(Conv2D(filters, [1,  1], strides=[1, 1], padding='same')(add_3x3_5x5_7x7))\n",
        "    mult_1x1_lower = Activation('sigmoid')(Conv2D(filters, [1,  1], strides=[1, 1], padding='same')(mul_3x3_5x5_7x7))\n",
        "    resampler_down_upper = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(add_1x1_upper) #AveragePooling2D\n",
        "    resampler_down_lower = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(mult_1x1_lower)\n",
        "    output_ms_conv_res_block = multiply([resampler_down_upper, resampler_down_lower])\n",
        "\n",
        "    theta_x_rb = Conv2D(filters, [1,  1], strides=[1, 1], padding='same')(res_block)\n",
        "    joint_conv_2x2_rb = Conv2D(filters, (2, 2), strides=(1, 1), padding='same', kernel_initializer = 'he_normal', kernel_regularizer=l2(1e-4))(theta_x_rb)\n",
        "    conv_3x3_rb = SpatialDropout2D(0.5)(Activation('relu')(Conv2D(filters, (3, 3), strides=(1, 1), padding='same', kernel_initializer = 'he_normal', kernel_regularizer=l2(1e-4))(joint_conv_2x2_rb)))\n",
        "    conv_5x5_rb = SpatialDropout2D(0.5)(Activation('relu')(Conv2D(filters, (5, 5), strides=(1, 1), padding='same', kernel_initializer = 'he_normal', kernel_regularizer=l2(1e-4))(joint_conv_2x2_rb)))\n",
        "    conv_7x7_rb = SpatialDropout2D(0.5)(Activation('relu')(Conv2D(filters, (7, 7), strides=(1, 1), padding='same', kernel_initializer = 'he_normal', kernel_regularizer=l2(1e-4))(joint_conv_2x2_rb)))\n",
        "    add_3x3_5x5_rb = add([conv_3x3_rb, conv_5x5_rb])\n",
        "    mult_3x3_5x5_rb = multiply([conv_3x3_rb, conv_5x5_rb])#multiply([conv_3x3_rb, conv_5x5_rb]) #Subtract()([conv_3x3_rb, conv_5x5_rb])\n",
        "    add_3x3_5x5_7x7_rb = Activation('sigmoid')(add([add_3x3_5x5_rb, conv_7x7_rb]))\n",
        "    mul_3x3_5x5_7x7_rb = Activation('sigmoid')(multiply([mult_3x3_5x5_rb, conv_7x7_rb]))#multiply([mult_3x3_5x5_rb, conv_7x7_rb]))) # Subtract()([mult_3x3_5x5_rb, conv_7x7_rb])\n",
        "    add_1x1_upper_rb = Activation('sigmoid')(Conv2D(filters, [1,  1], strides=[1, 1], padding='same')(add_3x3_5x5_7x7_rb))\n",
        "    mult_1x1_lower_rb = Activation('sigmoid')(Conv2D(filters, [1, 1], strides=[1, 1], padding='same')(mul_3x3_5x5_7x7_rb))\n",
        "    resampler_down_upper_rb = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(add_1x1_upper_rb)\n",
        "    resampler_down_lower_rb = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(mult_1x1_lower_rb)\n",
        "    output_ms_conv_res_block_rb = multiply([resampler_down_upper_rb, resampler_down_lower_rb])\n",
        "    \n",
        "    attn_outputs_mult = Activation('sigmoid')(multiply([output_ms_conv_res_block, output_ms_conv_res_block_rb]))\n",
        "    attn_output_1 = UpSampling2D(size=(2, 2))(attn_outputs_mult)\n",
        "    attn_output = multiply([attn_output_1, theta_x_rb])\n",
        "    return attn_output\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "def ResPath(filters, length, inp):\n",
        "    '''\n",
        "    ResPath\n",
        "\n",
        "    Arguments:\n",
        "        filters {int} -- [description]\n",
        "        length {int} -- length of ResPath\n",
        "        inp {keras layer} -- input layer\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "\n",
        "    shortcut = inp\n",
        "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
        "                         activation=None, padding='same')\n",
        "\n",
        "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
        "\n",
        "    out = add([shortcut, out])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    for i in range(length-1):\n",
        "\n",
        "        shortcut = out\n",
        "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
        "                             activation=None, padding='same')\n",
        "\n",
        "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
        "\n",
        "        out = add([shortcut, out])\n",
        "        out = Activation('relu')(out)\n",
        "        out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "# Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net)\n",
        "def rec_res_block(input_layer, filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n",
        "                  padding='same'):\n",
        "  skip_layer = input_layer\n",
        "  layer = skip_layer\n",
        "  for j in range(2):\n",
        "    for i in range(2):\n",
        "      if i == 0:\n",
        "        layer1 = Conv2D(filters, kernel_size, strides=stride, padding=padding)(layer)\n",
        "        if batch_normalization:\n",
        "          layer1 = BatchNormalization()(layer1)\n",
        "        layer1 = Activation('relu')(layer1)\n",
        "      layer1 = Conv2D(filters, kernel_size, strides=stride, padding=padding)(add([layer1, layer]))\n",
        "      if batch_normalization:\n",
        "        layer1 = BatchNormalization()(layer1)\n",
        "      layer1 = Activation('relu')(layer1)\n",
        "    layer = layer1\n",
        "  out_layer = add([layer, skip_layer])\n",
        "  return out_layer\n",
        "\n",
        "\n",
        "def DRRMSAN_multiscale_attention(height, width, n_channels, alpha_1, alpha_2, alpha_3, alpha_4):\n",
        "    '''\n",
        "    DRRMSAN Multiscale Attention Model\n",
        "\n",
        "    Arguments:\n",
        "        height {int} -- height of image\n",
        "        width {int} -- width of image\n",
        "        n_channels {int} -- number of channels in image\n",
        "\n",
        "    Returns:\n",
        "        [keras model] -- MultiResUNet model\n",
        "    '''\n",
        "\n",
        "\n",
        "    inputs = Input((height, width, n_channels))\n",
        "\n",
        "    # use average pool, maxpool and minpool to create different volumes of\n",
        "    # multiscaling, minpool is used here as a sort of regularizer noise in the feature\n",
        "    # space.  1/2 th the original scale first.\n",
        "\n",
        "    inp_1_2I = AveragePooling2D(pool_size=(2, 2))(inputs)\n",
        "    inp_1_2I_mxpool = MaxPooling2D(pool_size=(2, 2))(inputs)\n",
        "    inp_1_2I_minpool = MinPooling2D(inputs, pool_size=(2,2), strides=(1,1))\n",
        "    \"\"\"\n",
        "    tf.image.resize(\n",
        "              inputs, (int(height * 1/2), int(width * 1/2)), method=tf.image.ResizeMethod.BILINEAR, preserve_aspect_ratio=False,\n",
        "              antialias=False, name=None\n",
        "              )\n",
        "    \"\"\"\n",
        "    # 1/4 rth the original scale\n",
        "    inp_1_4I = AveragePooling2D(pool_size=(2, 2))(inp_1_2I)\n",
        "    inp_1_4I_mxpool = MaxPooling2D(pool_size=(2, 2))(inp_1_2I_mxpool)\n",
        "    inp_1_4I_minpool = MinPooling2D(inp_1_2I_minpool, pool_size=(2,2), strides=(1,1))\n",
        "    #inp_1_4I_minpool = MaxPooling2D(pool_size=(2, 2))(inp_1_2I_mxpool)\n",
        "    \"\"\"\n",
        "    tf.image.resize(\n",
        "              inputs, (int(height * 1/4), int(width * 1/4)), method=tf.image.ResizeMethod.BILINEAR, preserve_aspect_ratio=False,\n",
        "              antialias=False, name=None\n",
        "              )\n",
        "    \"\"\"\n",
        "    # 1/8 th the original scale\n",
        "    inp_1_8I = AveragePooling2D(pool_size=(2, 2))(inp_1_4I)\n",
        "    inp_1_8I_mxpool = MaxPooling2D(pool_size=(2, 2))(inp_1_4I_mxpool)\n",
        "    inp_1_8I_minpool = MinPooling2D(inp_1_4I_minpool, pool_size=(2,2), strides=(1,1))\n",
        "    \"\"\"\n",
        "              tf.image.resize(\n",
        "              inputs, (int(height * 1/8), int(width * 1/8)), method=tf.image.ResizeMethod.BILINEAR, preserve_aspect_ratio=False,\n",
        "              antialias=False, name=None\n",
        "              )\n",
        "    \"\"\"\n",
        "    # just pass through some conv and add\n",
        "    # for adding to multi res block 2, 32 filters\n",
        "    # use 50 - 50 \n",
        "    # Conv2D(filters, (3, 3), strides=(1,1), padding='same'\n",
        "    \n",
        "    # using different ratios for the volumes, can be improved by using\n",
        "    # Bayesian Optimization\n",
        "\n",
        "    total_1_2I = 51\n",
        "    per_mx_pool_1_2I = int(0.40 * total_1_2I)\n",
        "    per_avg_pool_1_2I = int(0.30 * total_1_2I)\n",
        "    per_min_pool_1_2I = int(0.05 * total_1_2I)\n",
        "    per_down_1_2I = int(total_1_2I - (per_mx_pool_1_2I + per_avg_pool_1_2I + per_min_pool_1_2I))\n",
        "\n",
        "    mrb2_1_2I_avgpool = Conv2D(per_avg_pool_1_2I, (3, 3), strides=(1,1), padding='same', name='side_left_1_avgpool')(inp_1_2I) \n",
        "    mrb2_1_2I_mxpool = Conv2D(per_mx_pool_1_2I, (3, 3), strides=(1,1), padding='same', name='side_left_1_mxpool')(inp_1_2I_mxpool)\n",
        "    mrb2_1_2I_minpool = Conv2D(per_min_pool_1_2I, (3, 3), strides=(1,1), padding='same', name='side_left_1_minpool')(inp_1_2I_minpool)\n",
        "\n",
        "    total_1_4I = 105\n",
        "    per_mx_pool_1_4I = int(0.40 * total_1_4I)\n",
        "    per_avg_pool_1_4I = int(0.30 * total_1_4I)\n",
        "    per_min_pool_1_4I = int(0.05 * total_1_4I)\n",
        "    # 52% to the down layer\n",
        "    per_down_1_4I = int(total_1_4I - (per_mx_pool_1_4I + per_avg_pool_1_4I + per_min_pool_1_4I))\n",
        "\n",
        "    mrb3_1_4I_avgpool = Conv2D(per_avg_pool_1_4I, (3, 3), strides=(1,1), padding='same', name='side_left_2_avgpool')(inp_1_4I) \n",
        "    mrb3_1_4I_mxpool = Conv2D(per_mx_pool_1_4I, (3, 3), strides=(1,1), padding='same', name='side_left_2_mxpool')(inp_1_4I_mxpool) \n",
        "    mrb3_1_4I_minpool = Conv2D(per_min_pool_1_4I, (3, 3), strides=(1,1), padding='same', name='side_left_2_minpool')(inp_1_4I_minpool) \n",
        "\n",
        "    total_1_8I = 212\n",
        "    per_mx_pool_1_8I = int(0.40 * total_1_8I)\n",
        "    per_avg_pool_1_8I = int(0.30 * total_1_8I)\n",
        "    per_min_pool_1_8I = int(0.05 * total_1_8I)\n",
        "    per_down_1_8I = int(total_1_8I - (per_mx_pool_1_8I + per_avg_pool_1_8I + per_min_pool_1_8I))\n",
        "\n",
        "    mrb4_1_8I_avgpool = Conv2D(per_avg_pool_1_8I, (3, 3), strides=(1,1), padding='same', name='side_left_3_avgpool')(inp_1_8I)\n",
        "    mrb4_1_8I_mxpool = Conv2D(per_mx_pool_1_8I, (3, 3), strides=(1,1), padding='same', name='side_left_3_mxpool')(inp_1_8I_mxpool)\n",
        "    mrb4_1_8I_minpool = Conv2D(per_min_pool_1_8I, (3, 3), strides=(1,1), padding='same', name='side_left_3_minpool')(inp_1_8I_minpool)\n",
        "\n",
        "\n",
        "    #==================================================================\n",
        "\n",
        "    mresblock1 = MultiResBlock(32, inputs)\n",
        "    #mresblock1 = rec_res_block(mresblock1, 51)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
        "    #===================\n",
        "    pool1 = Conv2D(per_down_1_2I, (3, 3), strides=(1,1), padding='same')(pool1)\n",
        "    left_block_1 = concatenate([pool1, mrb2_1_2I_avgpool, mrb2_1_2I_mxpool, mrb2_1_2I_minpool])\n",
        "    #left_block_1 = rec_res_block(left_block_1, total_1_2I)\n",
        "    #pool1 = multiply([pool1, mrb2_1_2I])\n",
        "    #pool1 = proposed_attention_block_2d(pool1, mresblock1,filters=51)\n",
        "    #===================\n",
        "    mresblock1 = ResPath(32, 4, mresblock1)\n",
        "\n",
        "    \n",
        "    mresblock2 = MultiResBlock(32*2, left_block_1)\n",
        "    #mresblock2 = rec_res_block(mresblock2, 105)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
        "    #===================\n",
        "    pool2 = Conv2D(per_down_1_4I, (3, 3), strides=(1,1), padding='same')(pool2)\n",
        "    left_block_2 = concatenate([pool2, mrb3_1_4I_avgpool, mrb3_1_4I_mxpool, mrb3_1_4I_minpool])\n",
        "    #left_block_2 = rec_res_block(left_block_2, total_1_4I)\n",
        "    #pool2 = multiply([pool2, mrb3_1_4I])\n",
        "    #pool2 = proposed_attention_block_2d(pool2, mresblock2,filters=105)\n",
        "    #===================\n",
        "    mresblock2 = ResPath(32*2, 3, mresblock2)\n",
        "\n",
        "    mresblock3 = MultiResBlock(32*4, left_block_2)\n",
        "    #mresblock3 = rec_res_block(mresblock3, 212)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
        "    #===================\n",
        "    pool3 = Conv2D(per_down_1_8I, (3, 3), strides=(1,1), padding='same')(pool3)\n",
        "    left_block_3 = concatenate([pool3, mrb4_1_8I_avgpool, mrb4_1_8I_mxpool, mrb4_1_8I_minpool])\n",
        "    #left_block_3 = rec_res_block(left_block_3, total_1_8I)\n",
        "    #pool3 = multiply([pool3, mrb4_1_8I])\n",
        "    #pool3 = proposed_attention_block_2d(pool3, mresblock3,filters=212)\n",
        "    #===================\n",
        "    mresblock3 = ResPath(32*4, 2, mresblock3)\n",
        "\n",
        "    mresblock4 = MultiResBlock(32*8, left_block_3)\n",
        "    #mresblock4 = rec_res_block(mresblock4, 426)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)\n",
        "    mresblock4 = ResPath(32*8, 1, mresblock4)\n",
        "\n",
        "\n",
        "    mresblock5 = MultiResBlock(32*16, pool4)\n",
        "    #mresblock5 = rec_res_block(mresblock5, 853)\n",
        "\n",
        "    #up6_add =  add([Conv2DTranspose(32*8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4])\n",
        "    #up6_dra = attention_up_and_concate(Conv2DTranspose(32*8, (2, 2), strides=(2, 2), padding='same', name='up6_dra')(mresblock5), mresblock4,filters=32*8)\n",
        "    up6 = attention_block_2d(Conv2DTranspose(32*8, (2, 2), strides=(2, 2), padding='same', name='up6')(mresblock5), mresblock4,filters=64)\n",
        "    up6 = add([up6, mresblock4])\n",
        "    \n",
        "    #concatenate([Conv2DTranspose(32*8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)\n",
        "    mresblock6 = MultiResBlock(32*8, up6)\n",
        "    #mresblock6 = rec_res_block(mresblock6, 426)\n",
        "    conv_6_up = Conv2D(212, (3, 3), padding='same', activation='relu', name='conv_6_up')(mresblock6)\n",
        "    #conv_6_up = rec_res_block(mresblock6, 426)\n",
        "    \n",
        "\n",
        "    #up7_add = add([Conv2DTranspose(32*4, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3])\n",
        "    #up7_dra = attention_up_and_concate(Conv2DTranspose(32*4, (2, 2), strides=(2, 2), padding='same', name='up7_dra')(mresblock6), mresblock3, filters = 32*4)\n",
        "    up7 = attention_block_2d(Conv2DTranspose(32*4, (2, 2), strides=(2, 2), padding='same', name='up7')(mresblock6), mresblock3, filters = 32*4)\n",
        "    up7 = add([up7, mresblock3])\n",
        "    mresblock7 = MultiResBlock(32*4, up7)\n",
        "    #mresblock7 = rec_res_block(mresblock7, 212)\n",
        "    conv_7_up = Conv2D(105, (3, 3), padding='same', activation='relu', name='conv_7_up')(mresblock7)\n",
        "    #conv_7_up = rec_res_block(mresblock7, 212)\n",
        "    \n",
        "\n",
        "    #up8_add = add([Conv2DTranspose(32*2, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2])\n",
        "    #up8_dra = attention_up_and_concate(Conv2DTranspose(32*2, (2, 2), strides=(2, 2), padding='same', name='up8_dra')(mresblock7), mresblock2, filters = 32*2)\n",
        "    up8 = attention_block_2d(Conv2DTranspose(32*2, (2, 2), strides=(2, 2), padding='same', name='up8')(mresblock7), mresblock2, filters = 32*2)\n",
        "    up8 = concatenate([up8, mresblock2])#,\n",
        "    mresblock8 = MultiResBlock(32*2, up8)\n",
        "    #mresblock8 = rec_res_block(mresblock8, 105)\n",
        "    conv_8_up = Conv2D(51, (3, 3), padding='same', activation='relu', name='conv_8_up')(mresblock8)\n",
        "    #conv_8_up = rec_res_block(conv_8_up, 51)\n",
        "\n",
        "    #up9_add = add([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(mresblock8), mresblock1])\n",
        "    #up9_dra = attention_up_and_concate(Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same', name='up9_dra')(mresblock8), mresblock1, filters = 32)\n",
        "    up9 = attention_block_2d(Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same', name='up9')(mresblock8), mresblock1, filters = 32)\n",
        "    up9 = add([up9, mresblock1])#\n",
        "    mresblock9 = MultiResBlock(32, up9)\n",
        "    #mresblock9 = rec_res_block(mresblock9, 51)\n",
        "    conv_9_up = Conv2D(32, (3, 3), padding='same', activation='relu', name='conv_8_up')(mresblock9)\n",
        "    #conv_9_up = rec_res_block(conv_9_up, 32)\n",
        "\n",
        "\n",
        "    side6 = UpSampling2D(size=(8, 8))(conv_6_up)\n",
        "    side7 = UpSampling2D(size=(4, 4))(conv_7_up)\n",
        "    side8 = UpSampling2D(size=(2, 2))(conv_8_up)\n",
        "\n",
        "    # the conv blocks on the right sides\n",
        "\n",
        "    out6 = Conv2D(1, (3, 3), activation='sigmoid', padding='same', kernel_initializer = 'he_normal', kernel_regularizer=l2(1e-4), name='side_6')(side6) # conv2d_bn(side6, 1, 1, 1, activation='none') #\n",
        "    out7 = Conv2D(1, (3, 3), activation='sigmoid', padding='same', kernel_initializer = 'he_normal', kernel_regularizer=l2(1e-4), name='side_7')(side7) # conv2d_bn(side7, 1, 1, 1, activation='none') #\n",
        "    out8 = Conv2D(1, (3, 3), activation='sigmoid', padding='same', kernel_initializer = 'he_normal', kernel_regularizer=l2(1e-4), name='side_8')(side8) # conv2d_bn(side8, 1, 1, 1, activation='none') #\n",
        "\n",
        "    out9 = conv2d_bn(mresblock9, 1, 3, 3, activation='sigmoid', padding='same')\n",
        "\n",
        "    # weighted averaging all the output masks obtained at different scales\n",
        "    # alpha_1 = least scale, alpha_4 = same scale as I\n",
        "\n",
        "    out10 = add([alpha_1 * out6, alpha_2 * out7, alpha_3 * out8, alpha_4 * out9])\n",
        "\n",
        "    #conv10 = conv2d_bn(out10, 1, 1, 1, activation='sigmoid')\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[out6, out7, out8, out9, out10])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVOH8A1pJM1u",
        "outputId": "e22d01cb-0c53-43c1-ff36-a884fdd66f4f"
      },
      "source": [
        "model = DRRMSAN_multiscale_attention(height=192, width=256, n_channels=3, alpha_1 = 0.1, alpha_2 = 0.1, alpha_3 = 0.1, alpha_4 = 0.6)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 192, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 192, 256, 8)  216         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 192, 256, 8)  24          conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 192, 256, 8)  0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 192, 256, 17) 1224        activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 192, 256, 17) 51          conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_3 (TFOpLambd ()                   0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.equal_6 (TFOpLambda)    (None, 192, 256, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 192, 256, 17) 0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_6 (TFOpLam ()                   0           tf.math.reduce_max_3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.cast_6 (TFOpLambda)          (None, 192, 256, 3)  0           tf.math.equal_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 192, 256, 26) 3978        activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_10 (TFOpLambda (None, 192, 256, 3)  0           tf.__operators__.add_6[0][0]     \n",
            "                                                                 tf.cast_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 192, 256, 26) 78          conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_7 (TFOpLam (None, 192, 256, 3)  0           tf.math.multiply_10[0][0]        \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 192, 256, 26) 0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.negative_6 (TFOpLambda) (None, 192, 256, 3)  0           tf.__operators__.add_7[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 192, 256, 51) 153         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 192, 256, 51) 0           activation_65[0][0]              \n",
            "                                                                 activation_66[0][0]              \n",
            "                                                                 activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_3 (TFO (None, 96, 128, 3)   0           tf.math.negative_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 192, 256, 51) 153         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 192, 256, 51) 204         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.negative_7 (TFOpLambda) (None, 96, 128, 3)   0           tf.compat.v1.nn.max_pool_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 192, 256, 51) 0           batch_normalization_85[0][0]     \n",
            "                                                                 batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.equal_7 (TFOpLambda)    (None, 96, 128, 3)   0           tf.math.negative_7[0][0]         \n",
            "                                                                 tf.__operators__.add_6[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 192, 256, 51) 0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.cast_7 (TFOpLambda)          (None, 96, 128, 3)   0           tf.math.equal_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 192, 256, 51) 204         activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_11 (TFOpLambda (None, 96, 128, 3)   0           tf.__operators__.add_6[0][0]     \n",
            "                                                                 tf.cast_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 96, 128, 51)  0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 96, 128, 3)   0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 96, 128, 3)   0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_3 (TFOpLambda) (None, 96, 128, 3)   0           tf.math.negative_7[0][0]         \n",
            "                                                                 tf.math.multiply_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 96, 128, 14)  6440        max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "side_left_1_avgpool (Conv2D)    (None, 96, 128, 15)  420         average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "side_left_1_mxpool (Conv2D)     (None, 96, 128, 20)  560         max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "side_left_1_minpool (Conv2D)    (None, 96, 128, 2)   56          tf.math.subtract_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 96, 128, 51)  0           conv2d_76[0][0]                  \n",
            "                                                                 side_left_1_avgpool[0][0]        \n",
            "                                                                 side_left_1_mxpool[0][0]         \n",
            "                                                                 side_left_1_minpool[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 96, 128, 17)  7803        concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 96, 128, 17)  51          conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 96, 128, 17)  0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 96, 128, 35)  5355        activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 96, 128, 35)  105         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_4 (TFOpLambd ()                   0           tf.math.subtract_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.equal_8 (TFOpLambda)    (None, 96, 128, 3)   0           tf.math.subtract_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 96, 128, 35)  0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_8 (TFOpLam ()                   0           tf.math.reduce_max_4[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.cast_8 (TFOpLambda)          (None, 96, 128, 3)   0           tf.math.equal_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 96, 128, 53)  16695       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_12 (TFOpLambda (None, 96, 128, 3)   0           tf.__operators__.add_8[0][0]     \n",
            "                                                                 tf.cast_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 96, 128, 53)  159         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_9 (TFOpLam (None, 96, 128, 3)   0           tf.math.multiply_12[0][0]        \n",
            "                                                                 tf.math.subtract_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 96, 128, 53)  0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.negative_8 (TFOpLambda) (None, 96, 128, 3)   0           tf.__operators__.add_9[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 96, 128, 105) 5355        concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 96, 128, 105) 0           activation_77[0][0]              \n",
            "                                                                 activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_4 (TFO (None, 48, 64, 3)    0           tf.math.negative_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 96, 128, 105) 315         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 96, 128, 105) 420         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.negative_9 (TFOpLambda) (None, 48, 64, 3)    0           tf.compat.v1.nn.max_pool_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 96, 128, 105) 0           batch_normalization_103[0][0]    \n",
            "                                                                 batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.equal_9 (TFOpLambda)    (None, 48, 64, 3)    0           tf.math.negative_9[0][0]         \n",
            "                                                                 tf.__operators__.add_8[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 96, 128, 105) 0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.cast_9 (TFOpLambda)          (None, 48, 64, 3)    0           tf.math.equal_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 96, 128, 105) 420         activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_13 (TFOpLambda (None, 48, 64, 3)    0           tf.__operators__.add_8[0][0]     \n",
            "                                                                 tf.cast_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 48, 64, 105)  0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 48, 64, 3)    0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 48, 64, 3)    0           max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_4 (TFOpLambda) (None, 48, 64, 3)    0           tf.math.negative_9[0][0]         \n",
            "                                                                 tf.math.multiply_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 48, 64, 27)   25542       max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "side_left_2_avgpool (Conv2D)    (None, 48, 64, 31)   868         average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "side_left_2_mxpool (Conv2D)     (None, 48, 64, 42)   1176        max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "side_left_2_minpool (Conv2D)    (None, 48, 64, 5)    140         tf.math.subtract_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 48, 64, 105)  0           conv2d_89[0][0]                  \n",
            "                                                                 side_left_2_avgpool[0][0]        \n",
            "                                                                 side_left_2_mxpool[0][0]         \n",
            "                                                                 side_left_2_minpool[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 48, 64, 35)   33075       concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 48, 64, 35)   105         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 48, 64, 35)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 48, 64, 71)   22365       activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 48, 64, 71)   213         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_max_5 (TFOpLambd ()                   0           tf.math.subtract_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.equal_10 (TFOpLambda)   (None, 48, 64, 3)    0           tf.math.subtract_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 48, 64, 71)   0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_10 (TFOpLa ()                   0           tf.math.reduce_max_5[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.cast_10 (TFOpLambda)         (None, 48, 64, 3)    0           tf.math.equal_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 48, 64, 106)  67734       activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_14 (TFOpLambda (None, 48, 64, 3)    0           tf.__operators__.add_10[0][0]    \n",
            "                                                                 tf.cast_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 48, 64, 106)  318         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_11 (TFOpLa (None, 48, 64, 3)    0           tf.math.multiply_14[0][0]        \n",
            "                                                                 tf.math.subtract_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 48, 64, 106)  0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.negative_10 (TFOpLambda (None, 48, 64, 3)    0           tf.__operators__.add_11[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 48, 64, 212)  22260       concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 48, 64, 212)  0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "                                                                 activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_5 (TFO (None, 24, 32, 3)    0           tf.math.negative_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 48, 64, 212)  636         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 48, 64, 212)  848         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.negative_11 (TFOpLambda (None, 24, 32, 3)    0           tf.compat.v1.nn.max_pool_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 48, 64, 212)  0           batch_normalization_118[0][0]    \n",
            "                                                                 batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.equal_11 (TFOpLambda)   (None, 24, 32, 3)    0           tf.math.negative_11[0][0]        \n",
            "                                                                 tf.__operators__.add_10[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 48, 64, 212)  0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.cast_11 (TFOpLambda)         (None, 24, 32, 3)    0           tf.math.equal_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 48, 64, 212)  848         activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_15 (TFOpLambda (None, 24, 32, 3)    0           tf.__operators__.add_10[0][0]    \n",
            "                                                                 tf.cast_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 24, 32, 212)  0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 24, 32, 3)    0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 24, 32, 3)    0           max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.subtract_5 (TFOpLambda) (None, 24, 32, 3)    0           tf.math.negative_11[0][0]        \n",
            "                                                                 tf.math.multiply_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 24, 32, 55)   104995      max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "side_left_3_avgpool (Conv2D)    (None, 24, 32, 63)   1764        average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "side_left_3_mxpool (Conv2D)     (None, 24, 32, 84)   2352        max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "side_left_3_minpool (Conv2D)    (None, 24, 32, 10)   280         tf.math.subtract_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 24, 32, 212)  0           conv2d_100[0][0]                 \n",
            "                                                                 side_left_3_avgpool[0][0]        \n",
            "                                                                 side_left_3_mxpool[0][0]         \n",
            "                                                                 side_left_3_minpool[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 24, 32, 71)   135468      concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 24, 32, 71)   213         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 24, 32, 71)   0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 24, 32, 142)  90738       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 24, 32, 142)  426         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 24, 32, 142)  0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 24, 32, 213)  272214      activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 24, 32, 213)  639         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 24, 32, 213)  0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 24, 32, 426)  90312       concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 24, 32, 426)  0           activation_95[0][0]              \n",
            "                                                                 activation_96[0][0]              \n",
            "                                                                 activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 24, 32, 426)  1278        conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 24, 32, 426)  1704        concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 24, 32, 426)  0           batch_normalization_130[0][0]    \n",
            "                                                                 batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 24, 32, 426)  0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 24, 32, 426)  1704        activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 12, 16, 426)  0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 12, 16, 142)  544428      max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 12, 16, 142)  426         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 12, 16, 142)  0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 12, 16, 284)  362952      activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 12, 16, 284)  852         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 12, 16, 284)  0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 12, 16, 427)  1091412     activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 12, 16, 427)  1281        conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 12, 16, 427)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 12, 16, 853)  363378      max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 12, 16, 853)  0           activation_101[0][0]             \n",
            "                                                                 activation_102[0][0]             \n",
            "                                                                 activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 24, 32, 256)  981504      batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 12, 16, 853)  2559        conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 12, 16, 853)  3412        concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 24, 32, 256)  109056      batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 24, 32, 256)  768         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 12, 16, 853)  0           batch_normalization_139[0][0]    \n",
            "                                                                 batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 24, 32, 256)  768         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 24, 32, 256)  0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 12, 16, 853)  0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 24, 32, 256)  0           batch_normalization_136[0][0]    \n",
            "                                                                 activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 12, 16, 853)  3412        activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 24, 32, 256)  0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "up6 (Conv2DTranspose)           (None, 24, 32, 256)  873728      batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 24, 32, 256)  1024        activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 24, 32, 64)   16448       up6[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 24, 32, 64)   16448       batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 24, 32, 64)   0           conv2d_115[0][0]                 \n",
            "                                                                 conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 24, 32, 64)   0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 24, 32, 1)    65          activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 24, 32, 1)    0           conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_4 (Multiply)           (None, 24, 32, 256)  0           up6[0][0]                        \n",
            "                                                                 activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 24, 32, 256)  0           multiply_4[0][0]                 \n",
            "                                                                 batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 24, 32, 71)   163584      add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 24, 32, 71)   213         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 24, 32, 71)   0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 24, 32, 142)  90738       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 48, 64, 128)  244224      batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 24, 32, 142)  426         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 48, 64, 128)  27136       batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 48, 64, 128)  384         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 24, 32, 142)  0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 48, 64, 128)  384         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 48, 64, 128)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 24, 32, 213)  272214      activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 48, 64, 128)  0           batch_normalization_124[0][0]    \n",
            "                                                                 activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 24, 32, 213)  639         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 48, 64, 128)  0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 24, 32, 213)  0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 48, 64, 128)  512         activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 24, 32, 426)  109056      add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 24, 32, 426)  0           activation_107[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 48, 64, 128)  147456      batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 24, 32, 426)  1278        conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 24, 32, 426)  1704        concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 48, 64, 128)  16384       batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 48, 64, 128)  384         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 24, 32, 426)  0           batch_normalization_145[0][0]    \n",
            "                                                                 batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 48, 64, 128)  384         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 48, 64, 128)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 24, 32, 426)  0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 48, 64, 128)  0           batch_normalization_127[0][0]    \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 24, 32, 426)  1704        activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 48, 64, 128)  0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "up7 (Conv2DTranspose)           (None, 48, 64, 128)  218240      batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 48, 64, 128)  512         activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 48, 64, 128)  16512       up7[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 48, 64, 128)  16512       batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 48, 64, 128)  0           conv2d_122[0][0]                 \n",
            "                                                                 conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 48, 64, 128)  0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 48, 64, 1)    129         activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 48, 64, 1)    0           conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 96, 128, 64)  60480       batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "multiply_5 (Multiply)           (None, 48, 64, 128)  0           up7[0][0]                        \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 96, 128, 64)  6720        batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 96, 128, 64)  192         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 48, 64, 128)  0           multiply_5[0][0]                 \n",
            "                                                                 batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 96, 128, 64)  192         conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 96, 128, 64)  0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 48, 64, 35)   40320       add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 96, 128, 64)  0           batch_normalization_109[0][0]    \n",
            "                                                                 activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 48, 64, 35)   105         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 96, 128, 64)  0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 48, 64, 35)   0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 96, 128, 64)  256         activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 48, 64, 71)   22365       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 96, 128, 64)  36864       batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 48, 64, 71)   213         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 96, 128, 64)  4096        batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 96, 128, 64)  192         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 48, 64, 71)   0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 96, 128, 64)  192         conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 96, 128, 64)  0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 48, 64, 106)  67734       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 96, 128, 64)  0           batch_normalization_112[0][0]    \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 48, 64, 106)  318         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 96, 128, 64)  0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 48, 64, 106)  0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 96, 128, 64)  256         activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 48, 64, 212)  27136       add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 48, 64, 212)  0           activation_113[0][0]             \n",
            "                                                                 activation_114[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 96, 128, 64)  36864       batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 48, 64, 212)  636         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 48, 64, 212)  848         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 96, 128, 64)  4096        batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 96, 128, 64)  192         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 48, 64, 212)  0           batch_normalization_151[0][0]    \n",
            "                                                                 batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 96, 128, 64)  192         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 96, 128, 64)  0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 48, 64, 212)  0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 96, 128, 64)  0           batch_normalization_115[0][0]    \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 48, 64, 212)  848         activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 96, 128, 64)  0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 192, 256, 32) 14688       batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up8 (Conv2DTranspose)           (None, 96, 128, 64)  54336       batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 96, 128, 64)  256         activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 192, 256, 32) 1632        batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 192, 256, 32) 96          conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 96, 128, 64)  4160        up8[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 96, 128, 64)  4160        batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 192, 256, 32) 96          conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 192, 256, 32) 0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_48 (Add)                    (None, 96, 128, 64)  0           conv2d_129[0][0]                 \n",
            "                                                                 conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 192, 256, 32) 0           batch_normalization_91[0][0]     \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 96, 128, 64)  0           add_48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 192, 256, 32) 0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 96, 128, 1)   65          activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 192, 256, 32) 128         activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 96, 128, 1)   0           conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 192, 256, 32) 9216        batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_6 (Multiply)           (None, 96, 128, 64)  0           up8[0][0]                        \n",
            "                                                                 activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 192, 256, 32) 1024        batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 192, 256, 32) 96          conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 96, 128, 128) 0           multiply_6[0][0]                 \n",
            "                                                                 batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 192, 256, 32) 96          conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 192, 256, 32) 0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 96, 128, 17)  19584       concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 192, 256, 32) 0           batch_normalization_94[0][0]     \n",
            "                                                                 activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 96, 128, 17)  51          conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 192, 256, 32) 0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 96, 128, 17)  0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 192, 256, 32) 128         activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 96, 128, 35)  5355        activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 192, 256, 32) 9216        batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 96, 128, 35)  105         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 192, 256, 32) 1024        batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 192, 256, 32) 96          conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 96, 128, 35)  0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 192, 256, 32) 96          conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 192, 256, 32) 0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 96, 128, 53)  16695       activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 192, 256, 32) 0           batch_normalization_97[0][0]     \n",
            "                                                                 activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 96, 128, 53)  159         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 192, 256, 32) 0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 96, 128, 53)  0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 192, 256, 32) 128         activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 96, 128, 105) 13440       concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 96, 128, 105) 0           activation_119[0][0]             \n",
            "                                                                 activation_120[0][0]             \n",
            "                                                                 activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 192, 256, 32) 9216        batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 96, 128, 105) 315         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 96, 128, 105) 420         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 192, 256, 32) 1024        batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 192, 256, 32) 96          conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 96, 128, 105) 0           batch_normalization_157[0][0]    \n",
            "                                                                 batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 192, 256, 32) 96          conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 192, 256, 32) 0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 96, 128, 105) 0           add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 192, 256, 32) 0           batch_normalization_100[0][0]    \n",
            "                                                                 activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 96, 128, 105) 420         activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 192, 256, 32) 0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "up9 (Conv2DTranspose)           (None, 192, 256, 32) 13472       batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 192, 256, 32) 128         activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 192, 256, 32) 1056        up9[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 192, 256, 32) 1056        batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_50 (Add)                    (None, 192, 256, 32) 0           conv2d_136[0][0]                 \n",
            "                                                                 conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 192, 256, 32) 0           add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 192, 256, 1)  33          activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 192, 256, 1)  0           conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_7 (Multiply)           (None, 192, 256, 32) 0           up9[0][0]                        \n",
            "                                                                 activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_51 (Add)                    (None, 192, 256, 32) 0           multiply_7[0][0]                 \n",
            "                                                                 batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 192, 256, 8)  2304        add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 192, 256, 8)  24          conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 192, 256, 8)  0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 192, 256, 17) 1224        activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 192, 256, 17) 51          conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 192, 256, 17) 0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 192, 256, 26) 3978        activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 192, 256, 26) 78          conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 192, 256, 26) 0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 192, 256, 51) 1632        add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 192, 256, 51) 0           activation_125[0][0]             \n",
            "                                                                 activation_126[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 192, 256, 51) 153         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 192, 256, 51) 204         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_52 (Add)                    (None, 192, 256, 51) 0           batch_normalization_163[0][0]    \n",
            "                                                                 batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 192, 256, 51) 0           add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 192, 256, 51) 204         activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_6_up (Conv2D)              (None, 24, 32, 212)  813020      batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_7_up (Conv2D)              (None, 48, 64, 105)  200445      batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv_8_up (Conv2D)              (None, 96, 128, 51)  48246       batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 192, 256, 1)  459         batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 192, 256, 212 0           conv_6_up[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 192, 256, 105 0           conv_7_up[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 192, 256, 51) 0           conv_8_up[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 192, 256, 1)  3           conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "side_6 (Conv2D)                 (None, 192, 256, 1)  1909        up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "side_7 (Conv2D)                 (None, 192, 256, 1)  946         up_sampling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "side_8 (Conv2D)                 (None, 192, 256, 1)  460         up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 192, 256, 1)  0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_16 (TFOpLambda (None, 192, 256, 1)  0           side_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_17 (TFOpLambda (None, 192, 256, 1)  0           side_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_18 (TFOpLambda (None, 192, 256, 1)  0           side_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_19 (TFOpLambda (None, 192, 256, 1)  0           activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_53 (Add)                    (None, 192, 256, 1)  0           tf.math.multiply_16[0][0]        \n",
            "                                                                 tf.math.multiply_17[0][0]        \n",
            "                                                                 tf.math.multiply_18[0][0]        \n",
            "                                                                 tf.math.multiply_19[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 8,205,389\n",
            "Trainable params: 8,180,867\n",
            "Non-trainable params: 24,522\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlJEioLNJMym"
      },
      "source": [
        "smooth = 1e-15\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def jacard(y_true, y_pred):\n",
        "\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum ( y_true_f * y_pred_f)\n",
        "    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
        "\n",
        "    return intersection/union"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BDDxCp5JMve"
      },
      "source": [
        "train_data = tf_dataset(x_train, y_train, batch=BATCH)\n",
        "valid_data = tf_dataset(x_val, y_val, batch=BATCH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqjbpzmOJMsj"
      },
      "source": [
        "opt = tf.keras.optimizers.Nadam(LR)\n",
        "metrics = [dice_coef, jacard, Recall(), Precision() ,'accuracy']\n",
        "model.compile(loss=dice_loss, optimizer=opt, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlsbcX0VJMpY"
      },
      "source": [
        "from datetime import datetime\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow import keras\n",
        "\n",
        "# for storing logs into tensorboard\n",
        "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "    #ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
        "    #EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=False),\n",
        "    ModelCheckpoint(\"./model_checkpoint\", monitor='val_loss'),\n",
        "    keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypi8ciRkJBCH"
      },
      "source": [
        "train_steps = len(x_train)//BATCH\n",
        "valid_steps = len(x_val)//BATCH\n",
        "\n",
        "if len(x_train) % BATCH != 0:\n",
        "    train_steps += 1\n",
        "if len(x_val) % BATCH != 0:\n",
        "    valid_steps += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ncVaNW7JA_m",
        "outputId": "c3cb87ce-c70c-430d-f4b6-539d4d6214c9"
      },
      "source": [
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=valid_data,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_steps=valid_steps,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "64/64 [==============================] - 43s 281ms/step - loss: 3.0268 - side_6_loss: 0.5565 - side_7_loss: 0.5903 - side_8_loss: 0.6055 - activation_129_loss: 0.6386 - add_53_loss: 0.6353 - side_6_dice_coef: 0.4435 - side_6_jacard: 0.2951 - side_6_recall_1: 0.7613 - side_6_precision_1: 0.3837 - side_6_accuracy: 0.5544 - side_7_dice_coef: 0.4097 - side_7_jacard: 0.2648 - side_7_recall_1: 0.6620 - side_7_precision_1: 0.3650 - side_7_accuracy: 0.5484 - side_8_dice_coef: 0.3945 - side_8_jacard: 0.2528 - side_8_recall_1: 0.7022 - side_8_precision_1: 0.3267 - side_8_accuracy: 0.4706 - activation_129_dice_coef: 0.3614 - activation_129_jacard: 0.2266 - activation_129_recall_1: 0.5233 - activation_129_precision_1: 0.3003 - activation_129_accuracy: 0.4853 - add_53_dice_coef: 0.3647 - add_53_jacard: 0.2285 - add_53_recall_1: 0.4686 - add_53_precision_1: 0.3561 - add_53_accuracy: 0.5817 - val_loss: 2.9945 - val_side_6_loss: 0.6707 - val_side_7_loss: 0.5739 - val_side_8_loss: 0.5930 - val_activation_129_loss: 0.5608 - val_add_53_loss: 0.5954 - val_side_6_dice_coef: 0.3293 - val_side_6_jacard: 0.2000 - val_side_6_recall_1: 1.4081e-04 - val_side_6_precision_1: 0.1175 - val_side_6_accuracy: 0.6023 - val_side_7_dice_coef: 0.4261 - val_side_7_jacard: 0.2790 - val_side_7_recall_1: 0.9017 - val_side_7_precision_1: 0.4271 - val_side_7_accuracy: 0.4804 - val_side_8_dice_coef: 0.4070 - val_side_8_jacard: 0.2628 - val_side_8_recall_1: 0.0586 - val_side_8_precision_1: 0.3422 - val_side_8_accuracy: 0.5812 - val_activation_129_dice_coef: 0.4392 - val_activation_129_jacard: 0.2908 - val_activation_129_recall_1: 0.9974 - val_activation_129_precision_1: 0.3994 - val_activation_129_accuracy: 0.4029 - val_add_53_dice_coef: 0.4046 - val_add_53_jacard: 0.2601 - val_add_53_recall_1: 8.4807e-05 - val_add_53_precision_1: 0.1398 - val_add_53_accuracy: 0.6025\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 2/20\n",
            "64/64 [==============================] - 11s 174ms/step - loss: 2.3190 - side_6_loss: 0.3008 - side_7_loss: 0.3875 - side_8_loss: 0.5066 - activation_129_loss: 0.5813 - add_53_loss: 0.5423 - side_6_dice_coef: 0.6992 - side_6_jacard: 0.5544 - side_6_recall_1: 0.8873 - side_6_precision_1: 0.6835 - side_6_accuracy: 0.8411 - side_7_dice_coef: 0.6125 - side_7_jacard: 0.4544 - side_7_recall_1: 0.8959 - side_7_precision_1: 0.5758 - side_7_accuracy: 0.7680 - side_8_dice_coef: 0.4934 - side_8_jacard: 0.3362 - side_8_recall_1: 0.8835 - side_8_precision_1: 0.4423 - side_8_accuracy: 0.6263 - activation_129_dice_coef: 0.4187 - activation_129_jacard: 0.2713 - activation_129_recall_1: 0.6708 - activation_129_precision_1: 0.4036 - activation_129_accuracy: 0.5995 - add_53_dice_coef: 0.4577 - add_53_jacard: 0.3031 - add_53_recall_1: 0.7496 - add_53_precision_1: 0.6387 - add_53_accuracy: 0.7955 - val_loss: 3.3373 - val_side_6_loss: 0.8491 - val_side_7_loss: 0.6344 - val_side_8_loss: 0.6783 - val_activation_129_loss: 0.5583 - val_add_53_loss: 0.6166 - val_side_6_dice_coef: 0.1509 - val_side_6_jacard: 0.0821 - val_side_6_recall_1: 0.0000e+00 - val_side_6_precision_1: 0.0000e+00 - val_side_6_accuracy: 0.6027 - val_side_7_dice_coef: 0.3656 - val_side_7_jacard: 0.2286 - val_side_7_recall_1: 0.0384 - val_side_7_precision_1: 0.7160 - val_side_7_accuracy: 0.6119 - val_side_8_dice_coef: 0.3217 - val_side_8_jacard: 0.1947 - val_side_8_recall_1: 0.0000e+00 - val_side_8_precision_1: 0.0000e+00 - val_side_8_accuracy: 0.6026 - val_activation_129_dice_coef: 0.4417 - val_activation_129_jacard: 0.2924 - val_activation_129_recall_1: 0.9324 - val_activation_129_precision_1: 0.4551 - val_activation_129_accuracy: 0.5296 - val_add_53_dice_coef: 0.3834 - val_add_53_jacard: 0.2420 - val_add_53_recall_1: 0.0000e+00 - val_add_53_precision_1: 0.0000e+00 - val_add_53_accuracy: 0.6027\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 3/20\n",
            "64/64 [==============================] - 11s 174ms/step - loss: 1.9111 - side_6_loss: 0.2041 - side_7_loss: 0.2758 - side_8_loss: 0.4119 - activation_129_loss: 0.5322 - add_53_loss: 0.4865 - side_6_dice_coef: 0.7959 - side_6_jacard: 0.6734 - side_6_recall_1: 0.8343 - side_6_precision_1: 0.8306 - side_6_accuracy: 0.8979 - side_7_dice_coef: 0.7242 - side_7_jacard: 0.5828 - side_7_recall_1: 0.8732 - side_7_precision_1: 0.7357 - side_7_accuracy: 0.8666 - side_8_dice_coef: 0.5881 - side_8_jacard: 0.4273 - side_8_recall_1: 0.8875 - side_8_precision_1: 0.5729 - side_8_accuracy: 0.7653 - activation_129_dice_coef: 0.4678 - activation_129_jacard: 0.3117 - activation_129_recall_1: 0.7750 - activation_129_precision_1: 0.5020 - activation_129_accuracy: 0.6986 - add_53_dice_coef: 0.5135 - add_53_jacard: 0.3515 - add_53_recall_1: 0.7975 - add_53_precision_1: 0.7819 - add_53_accuracy: 0.8709 - val_loss: 3.5992 - val_side_6_loss: 0.9090 - val_side_7_loss: 0.6370 - val_side_8_loss: 0.8349 - val_activation_129_loss: 0.5746 - val_add_53_loss: 0.6432 - val_side_6_dice_coef: 0.0910 - val_side_6_jacard: 0.0483 - val_side_6_recall_1: 0.0000e+00 - val_side_6_precision_1: 0.0000e+00 - val_side_6_accuracy: 0.6027 - val_side_7_dice_coef: 0.3630 - val_side_7_jacard: 0.2280 - val_side_7_recall_1: 0.1875 - val_side_7_precision_1: 0.9882 - val_side_7_accuracy: 0.6763 - val_side_8_dice_coef: 0.1651 - val_side_8_jacard: 0.0904 - val_side_8_recall_1: 0.0000e+00 - val_side_8_precision_1: 0.0000e+00 - val_side_8_accuracy: 0.6027 - val_activation_129_dice_coef: 0.4254 - val_activation_129_jacard: 0.2767 - val_activation_129_recall_1: 0.4204 - val_activation_129_precision_1: 0.6431 - val_activation_129_accuracy: 0.6770 - val_add_53_dice_coef: 0.3568 - val_add_53_jacard: 0.2200 - val_add_53_recall_1: 1.6001e-06 - val_add_53_precision_1: 0.5000 - val_add_53_accuracy: 0.6027\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 4/20\n",
            "64/64 [==============================] - 11s 174ms/step - loss: 1.6829 - side_6_loss: 0.1751 - side_7_loss: 0.2054 - side_8_loss: 0.3405 - activation_129_loss: 0.5050 - add_53_loss: 0.4563 - side_6_dice_coef: 0.8249 - side_6_jacard: 0.7121 - side_6_recall_1: 0.8183 - side_6_precision_1: 0.8706 - side_6_accuracy: 0.9076 - side_7_dice_coef: 0.7946 - side_7_jacard: 0.6713 - side_7_recall_1: 0.8383 - side_7_precision_1: 0.8444 - side_7_accuracy: 0.9040 - side_8_dice_coef: 0.6595 - side_8_jacard: 0.5050 - side_8_recall_1: 0.8757 - side_8_precision_1: 0.6704 - side_8_accuracy: 0.8319 - activation_129_dice_coef: 0.4950 - activation_129_jacard: 0.3354 - activation_129_recall_1: 0.8165 - activation_129_precision_1: 0.5656 - activation_129_accuracy: 0.7542 - add_53_dice_coef: 0.5437 - add_53_jacard: 0.3791 - add_53_recall_1: 0.8072 - add_53_precision_1: 0.8394 - add_53_accuracy: 0.8943 - val_loss: 3.3481 - val_side_6_loss: 0.7867 - val_side_7_loss: 0.5357 - val_side_8_loss: 0.8359 - val_activation_129_loss: 0.5668 - val_add_53_loss: 0.6225 - val_side_6_dice_coef: 0.2133 - val_side_6_jacard: 0.1287 - val_side_6_recall_1: 0.0752 - val_side_6_precision_1: 1.0000 - val_side_6_accuracy: 0.6326 - val_side_7_dice_coef: 0.4643 - val_side_7_jacard: 0.3206 - val_side_7_recall_1: 0.3143 - val_side_7_precision_1: 0.9860 - val_side_7_accuracy: 0.7258 - val_side_8_dice_coef: 0.1641 - val_side_8_jacard: 0.0907 - val_side_8_recall_1: 0.0019 - val_side_8_precision_1: 0.9676 - val_side_8_accuracy: 0.6034 - val_activation_129_dice_coef: 0.4332 - val_activation_129_jacard: 0.2820 - val_activation_129_recall_1: 0.3873 - val_activation_129_precision_1: 0.7448 - val_activation_129_accuracy: 0.7038 - val_add_53_dice_coef: 0.3775 - val_add_53_jacard: 0.2355 - val_add_53_recall_1: 0.0713 - val_add_53_precision_1: 0.9988 - val_add_53_accuracy: 0.6309\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 5/20\n",
            "64/64 [==============================] - 11s 173ms/step - loss: 1.5454 - side_6_loss: 0.1593 - side_7_loss: 0.1728 - side_8_loss: 0.2827 - activation_129_loss: 0.4906 - add_53_loss: 0.4394 - side_6_dice_coef: 0.8407 - side_6_jacard: 0.7342 - side_6_recall_1: 0.8214 - side_6_precision_1: 0.8880 - side_6_accuracy: 0.9140 - side_7_dice_coef: 0.8272 - side_7_jacard: 0.7155 - side_7_recall_1: 0.8252 - side_7_precision_1: 0.8823 - side_7_accuracy: 0.9132 - side_8_dice_coef: 0.7173 - side_8_jacard: 0.5735 - side_8_recall_1: 0.8641 - side_8_precision_1: 0.7477 - side_8_accuracy: 0.8705 - activation_129_dice_coef: 0.5094 - activation_129_jacard: 0.3483 - activation_129_recall_1: 0.8368 - activation_129_precision_1: 0.6059 - activation_129_accuracy: 0.7854 - add_53_dice_coef: 0.5606 - add_53_jacard: 0.3952 - add_53_recall_1: 0.8137 - add_53_precision_1: 0.8671 - add_53_accuracy: 0.9053 - val_loss: 2.5311 - val_side_6_loss: 0.5024 - val_side_7_loss: 0.3973 - val_side_8_loss: 0.5510 - val_activation_129_loss: 0.5329 - val_add_53_loss: 0.5469 - val_side_6_dice_coef: 0.4976 - val_side_6_jacard: 0.3743 - val_side_6_recall_1: 0.3364 - val_side_6_precision_1: 0.9913 - val_side_6_accuracy: 0.7351 - val_side_7_dice_coef: 0.6027 - val_side_7_jacard: 0.4732 - val_side_7_recall_1: 0.4597 - val_side_7_precision_1: 0.9755 - val_side_7_accuracy: 0.7807 - val_side_8_dice_coef: 0.4490 - val_side_8_jacard: 0.3095 - val_side_8_recall_1: 0.3073 - val_side_8_precision_1: 0.9234 - val_side_8_accuracy: 0.7146 - val_activation_129_dice_coef: 0.4671 - val_activation_129_jacard: 0.3109 - val_activation_129_recall_1: 0.5350 - val_activation_129_precision_1: 0.7588 - val_activation_129_accuracy: 0.7477 - val_add_53_dice_coef: 0.4531 - val_add_53_jacard: 0.2988 - val_add_53_recall_1: 0.3784 - val_add_53_precision_1: 0.9600 - val_add_53_accuracy: 0.7467\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 6/20\n",
            "64/64 [==============================] - 11s 173ms/step - loss: 1.4523 - side_6_loss: 0.1461 - side_7_loss: 0.1567 - side_8_loss: 0.2384 - activation_129_loss: 0.4818 - add_53_loss: 0.4286 - side_6_dice_coef: 0.8539 - side_6_jacard: 0.7528 - side_6_recall_1: 0.8283 - side_6_precision_1: 0.9015 - side_6_accuracy: 0.9201 - side_7_dice_coef: 0.8433 - side_7_jacard: 0.7381 - side_7_recall_1: 0.8240 - side_7_precision_1: 0.8980 - side_7_accuracy: 0.9178 - side_8_dice_coef: 0.7616 - side_8_jacard: 0.6294 - side_8_recall_1: 0.8529 - side_8_precision_1: 0.8098 - side_8_accuracy: 0.8946 - activation_129_dice_coef: 0.5182 - activation_129_jacard: 0.3564 - activation_129_recall_1: 0.8490 - activation_129_precision_1: 0.6337 - activation_129_accuracy: 0.8054 - add_53_dice_coef: 0.5714 - add_53_jacard: 0.4057 - add_53_recall_1: 0.8191 - add_53_precision_1: 0.8845 - add_53_accuracy: 0.9123 - val_loss: 1.9868 - val_side_6_loss: 0.3453 - val_side_7_loss: 0.3062 - val_side_8_loss: 0.3567 - val_activation_129_loss: 0.4950 - val_add_53_loss: 0.4831 - val_side_6_dice_coef: 0.6547 - val_side_6_jacard: 0.5402 - val_side_6_recall_1: 0.4917 - val_side_6_precision_1: 0.9611 - val_side_6_accuracy: 0.7901 - val_side_7_dice_coef: 0.6938 - val_side_7_jacard: 0.5773 - val_side_7_recall_1: 0.5430 - val_side_7_precision_1: 0.9538 - val_side_7_accuracy: 0.8080 - val_side_8_dice_coef: 0.6433 - val_side_8_jacard: 0.5034 - val_side_8_recall_1: 0.5542 - val_side_8_precision_1: 0.8549 - val_side_8_accuracy: 0.7855 - val_activation_129_dice_coef: 0.5050 - val_activation_129_jacard: 0.3447 - val_activation_129_recall_1: 0.6667 - val_activation_129_precision_1: 0.7256 - val_activation_129_accuracy: 0.7674 - val_add_53_dice_coef: 0.5169 - val_add_53_jacard: 0.3553 - val_add_53_recall_1: 0.5375 - val_add_53_precision_1: 0.9001 - val_add_53_accuracy: 0.7925\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 7/20\n",
            "64/64 [==============================] - 11s 174ms/step - loss: 1.3802 - side_6_loss: 0.1329 - side_7_loss: 0.1443 - side_8_loss: 0.2061 - activation_129_loss: 0.4756 - add_53_loss: 0.4206 - side_6_dice_coef: 0.8671 - side_6_jacard: 0.7720 - side_6_recall_1: 0.8399 - side_6_precision_1: 0.9139 - side_6_accuracy: 0.9271 - side_7_dice_coef: 0.8557 - side_7_jacard: 0.7558 - side_7_recall_1: 0.8281 - side_7_precision_1: 0.9097 - side_7_accuracy: 0.9225 - side_8_dice_coef: 0.7939 - side_8_jacard: 0.6719 - side_8_recall_1: 0.8448 - side_8_precision_1: 0.8510 - side_8_accuracy: 0.9079 - activation_129_dice_coef: 0.5244 - activation_129_jacard: 0.3622 - activation_129_recall_1: 0.8574 - activation_129_precision_1: 0.6545 - activation_129_accuracy: 0.8195 - add_53_dice_coef: 0.5794 - add_53_jacard: 0.4135 - add_53_recall_1: 0.8250 - add_53_precision_1: 0.8977 - add_53_accuracy: 0.9180 - val_loss: 1.7550 - val_side_6_loss: 0.2716 - val_side_7_loss: 0.2641 - val_side_8_loss: 0.3055 - val_activation_129_loss: 0.4653 - val_add_53_loss: 0.4479 - val_side_6_dice_coef: 0.7284 - val_side_6_jacard: 0.6132 - val_side_6_recall_1: 0.5849 - val_side_6_precision_1: 0.9331 - val_side_6_accuracy: 0.8184 - val_side_7_dice_coef: 0.7359 - val_side_7_jacard: 0.6221 - val_side_7_recall_1: 0.6011 - val_side_7_precision_1: 0.9253 - val_side_7_accuracy: 0.8222 - val_side_8_dice_coef: 0.6945 - val_side_8_jacard: 0.5552 - val_side_8_recall_1: 0.6467 - val_side_8_precision_1: 0.7931 - val_side_8_accuracy: 0.7926 - val_activation_129_dice_coef: 0.5347 - val_activation_129_jacard: 0.3728 - val_activation_129_recall_1: 0.7366 - val_activation_129_precision_1: 0.6577 - val_activation_129_accuracy: 0.7430 - val_add_53_dice_coef: 0.5521 - val_add_53_jacard: 0.3883 - val_add_53_recall_1: 0.6167 - val_add_53_precision_1: 0.8700 - val_add_53_accuracy: 0.8111\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 8/20\n",
            "64/64 [==============================] - 11s 173ms/step - loss: 1.3200 - side_6_loss: 0.1197 - side_7_loss: 0.1321 - side_8_loss: 0.1826 - activation_129_loss: 0.4708 - add_53_loss: 0.4142 - side_6_dice_coef: 0.8803 - side_6_jacard: 0.7916 - side_6_recall_1: 0.8537 - side_6_precision_1: 0.9257 - side_6_accuracy: 0.9345 - side_7_dice_coef: 0.8679 - side_7_jacard: 0.7735 - side_7_recall_1: 0.8359 - side_7_precision_1: 0.9205 - side_7_accuracy: 0.9279 - side_8_dice_coef: 0.8174 - side_8_jacard: 0.7038 - side_8_recall_1: 0.8406 - side_8_precision_1: 0.8775 - side_8_accuracy: 0.9157 - activation_129_dice_coef: 0.5292 - activation_129_jacard: 0.3668 - activation_129_recall_1: 0.8638 - activation_129_precision_1: 0.6716 - activation_129_accuracy: 0.8306 - add_53_dice_coef: 0.5858 - add_53_jacard: 0.4199 - add_53_recall_1: 0.8319 - add_53_precision_1: 0.9089 - add_53_accuracy: 0.9233 - val_loss: 1.6171 - val_side_6_loss: 0.2249 - val_side_7_loss: 0.2354 - val_side_8_loss: 0.2859 - val_activation_129_loss: 0.4451 - val_add_53_loss: 0.4253 - val_side_6_dice_coef: 0.7751 - val_side_6_jacard: 0.6618 - val_side_6_recall_1: 0.6561 - val_side_6_precision_1: 0.9173 - val_side_6_accuracy: 0.8399 - val_side_7_dice_coef: 0.7646 - val_side_7_jacard: 0.6515 - val_side_7_recall_1: 0.6519 - val_side_7_precision_1: 0.9022 - val_side_7_accuracy: 0.8336 - val_side_8_dice_coef: 0.7141 - val_side_8_jacard: 0.5784 - val_side_8_recall_1: 0.6874 - val_side_8_precision_1: 0.7660 - val_side_8_accuracy: 0.7924 - val_activation_129_dice_coef: 0.5549 - val_activation_129_jacard: 0.3929 - val_activation_129_recall_1: 0.7699 - val_activation_129_precision_1: 0.6255 - val_activation_129_accuracy: 0.7255 - val_add_53_dice_coef: 0.5747 - val_add_53_jacard: 0.4107 - val_add_53_recall_1: 0.6689 - val_add_53_precision_1: 0.8379 - val_add_53_accuracy: 0.8170\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 9/20\n",
            "64/64 [==============================] - 11s 174ms/step - loss: 1.2675 - side_6_loss: 0.1076 - side_7_loss: 0.1192 - side_8_loss: 0.1648 - activation_129_loss: 0.4667 - add_53_loss: 0.4086 - side_6_dice_coef: 0.8924 - side_6_jacard: 0.8101 - side_6_recall_1: 0.8661 - side_6_precision_1: 0.9355 - side_6_accuracy: 0.9410 - side_7_dice_coef: 0.8808 - side_7_jacard: 0.7929 - side_7_recall_1: 0.8467 - side_7_precision_1: 0.9318 - side_7_accuracy: 0.9343 - side_8_dice_coef: 0.8352 - side_8_jacard: 0.7285 - side_8_recall_1: 0.8397 - side_8_precision_1: 0.8954 - side_8_accuracy: 0.9213 - activation_129_dice_coef: 0.5333 - activation_129_jacard: 0.3707 - activation_129_recall_1: 0.8692 - activation_129_precision_1: 0.6860 - activation_129_accuracy: 0.8397 - add_53_dice_coef: 0.5914 - add_53_jacard: 0.4255 - add_53_recall_1: 0.8400 - add_53_precision_1: 0.9193 - add_53_accuracy: 0.9287 - val_loss: 1.5207 - val_side_6_loss: 0.1981 - val_side_7_loss: 0.2141 - val_side_8_loss: 0.2652 - val_activation_129_loss: 0.4324 - val_add_53_loss: 0.4103 - val_side_6_dice_coef: 0.8019 - val_side_6_jacard: 0.6912 - val_side_6_recall_1: 0.7007 - val_side_6_precision_1: 0.9114 - val_side_6_accuracy: 0.8540 - val_side_7_dice_coef: 0.7859 - val_side_7_jacard: 0.6749 - val_side_7_recall_1: 0.6888 - val_side_7_precision_1: 0.8975 - val_side_7_accuracy: 0.8451 - val_side_8_dice_coef: 0.7348 - val_side_8_jacard: 0.6054 - val_side_8_recall_1: 0.7070 - val_side_8_precision_1: 0.7790 - val_side_8_accuracy: 0.8039 - val_activation_129_dice_coef: 0.5676 - val_activation_129_jacard: 0.4059 - val_activation_129_recall_1: 0.7863 - val_activation_129_precision_1: 0.6177 - val_activation_129_accuracy: 0.7217 - val_add_53_dice_coef: 0.5897 - val_add_53_jacard: 0.4262 - val_add_53_recall_1: 0.7002 - val_add_53_precision_1: 0.8233 - val_add_53_accuracy: 0.8212\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 10/20\n",
            "64/64 [==============================] - 11s 173ms/step - loss: 1.2197 - side_6_loss: 0.0969 - side_7_loss: 0.1058 - side_8_loss: 0.1497 - activation_129_loss: 0.4632 - add_53_loss: 0.4035 - side_6_dice_coef: 0.9031 - side_6_jacard: 0.8269 - side_6_recall_1: 0.8783 - side_6_precision_1: 0.9430 - side_6_accuracy: 0.9468 - side_7_dice_coef: 0.8942 - side_7_jacard: 0.8135 - side_7_recall_1: 0.8596 - side_7_precision_1: 0.9427 - side_7_accuracy: 0.9412 - side_8_dice_coef: 0.8503 - side_8_jacard: 0.7497 - side_8_recall_1: 0.8420 - side_8_precision_1: 0.9100 - side_8_accuracy: 0.9265 - activation_129_dice_coef: 0.5368 - activation_129_jacard: 0.3741 - activation_129_recall_1: 0.8743 - activation_129_precision_1: 0.6989 - activation_129_accuracy: 0.8477 - add_53_dice_coef: 0.5965 - add_53_jacard: 0.4307 - add_53_recall_1: 0.8491 - add_53_precision_1: 0.9293 - add_53_accuracy: 0.9343 - val_loss: 1.4664 - val_side_6_loss: 0.1880 - val_side_7_loss: 0.2025 - val_side_8_loss: 0.2491 - val_activation_129_loss: 0.4247 - val_add_53_loss: 0.4015 - val_side_6_dice_coef: 0.8120 - val_side_6_jacard: 0.7012 - val_side_6_recall_1: 0.7217 - val_side_6_precision_1: 0.9077 - val_side_6_accuracy: 0.8603 - val_side_7_dice_coef: 0.7975 - val_side_7_jacard: 0.6872 - val_side_7_recall_1: 0.7060 - val_side_7_precision_1: 0.8969 - val_side_7_accuracy: 0.8510 - val_side_8_dice_coef: 0.7509 - val_side_8_jacard: 0.6265 - val_side_8_recall_1: 0.7127 - val_side_8_precision_1: 0.7986 - val_side_8_accuracy: 0.8144 - val_activation_129_dice_coef: 0.5753 - val_activation_129_jacard: 0.4140 - val_activation_129_recall_1: 0.7955 - val_activation_129_precision_1: 0.6275 - val_activation_129_accuracy: 0.7311 - val_add_53_dice_coef: 0.5985 - val_add_53_jacard: 0.4353 - val_add_53_recall_1: 0.7143 - val_add_53_precision_1: 0.8251 - val_add_53_accuracy: 0.8264\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 11/20\n",
            "64/64 [==============================] - 11s 173ms/step - loss: 1.1733 - side_6_loss: 0.0868 - side_7_loss: 0.0928 - side_8_loss: 0.1348 - activation_129_loss: 0.4599 - add_53_loss: 0.3985 - side_6_dice_coef: 0.9132 - side_6_jacard: 0.8433 - side_6_recall_1: 0.8911 - side_6_precision_1: 0.9491 - side_6_accuracy: 0.9523 - side_7_dice_coef: 0.9072 - side_7_jacard: 0.8342 - side_7_recall_1: 0.8740 - side_7_precision_1: 0.9523 - side_7_accuracy: 0.9482 - side_8_dice_coef: 0.8652 - side_8_jacard: 0.7711 - side_8_recall_1: 0.8471 - side_8_precision_1: 0.9253 - side_8_accuracy: 0.9325 - activation_129_dice_coef: 0.5401 - activation_129_jacard: 0.3773 - activation_129_recall_1: 0.8794 - activation_129_precision_1: 0.7113 - activation_129_accuracy: 0.8552 - add_53_dice_coef: 0.6015 - add_53_jacard: 0.4359 - add_53_recall_1: 0.8592 - add_53_precision_1: 0.9394 - add_53_accuracy: 0.9402 - val_loss: 1.4361 - val_side_6_loss: 0.1864 - val_side_7_loss: 0.1957 - val_side_8_loss: 0.2369 - val_activation_129_loss: 0.4200 - val_add_53_loss: 0.3965 - val_side_6_dice_coef: 0.8136 - val_side_6_jacard: 0.7008 - val_side_6_recall_1: 0.7328 - val_side_6_precision_1: 0.9032 - val_side_6_accuracy: 0.8626 - val_side_7_dice_coef: 0.8043 - val_side_7_jacard: 0.6930 - val_side_7_recall_1: 0.7175 - val_side_7_precision_1: 0.8957 - val_side_7_accuracy: 0.8546 - val_side_8_dice_coef: 0.7631 - val_side_8_jacard: 0.6413 - val_side_8_recall_1: 0.7139 - val_side_8_precision_1: 0.8203 - val_side_8_accuracy: 0.8242 - val_activation_129_dice_coef: 0.5800 - val_activation_129_jacard: 0.4188 - val_activation_129_recall_1: 0.8013 - val_activation_129_precision_1: 0.6421 - val_activation_129_accuracy: 0.7436 - val_add_53_dice_coef: 0.6035 - val_add_53_jacard: 0.4405 - val_add_53_recall_1: 0.7229 - val_add_53_precision_1: 0.8328 - val_add_53_accuracy: 0.8322\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 12/20\n",
            "64/64 [==============================] - 11s 173ms/step - loss: 1.1293 - side_6_loss: 0.0778 - side_7_loss: 0.0810 - side_8_loss: 0.1194 - activation_129_loss: 0.4567 - add_53_loss: 0.3938 - side_6_dice_coef: 0.9222 - side_6_jacard: 0.8582 - side_6_recall_1: 0.9018 - side_6_precision_1: 0.9542 - side_6_accuracy: 0.9570 - side_7_dice_coef: 0.9190 - side_7_jacard: 0.8534 - side_7_recall_1: 0.8885 - side_7_precision_1: 0.9599 - side_7_accuracy: 0.9547 - side_8_dice_coef: 0.8806 - side_8_jacard: 0.7938 - side_8_recall_1: 0.8544 - side_8_precision_1: 0.9411 - side_8_accuracy: 0.9393 - activation_129_dice_coef: 0.5433 - activation_129_jacard: 0.3804 - activation_129_recall_1: 0.8848 - activation_129_precision_1: 0.7231 - activation_129_accuracy: 0.8624 - add_53_dice_coef: 0.6062 - add_53_jacard: 0.4409 - add_53_recall_1: 0.8700 - add_53_precision_1: 0.9497 - add_53_accuracy: 0.9463 - val_loss: 1.4118 - val_side_6_loss: 0.1869 - val_side_7_loss: 0.1908 - val_side_8_loss: 0.2242 - val_activation_129_loss: 0.4168 - val_add_53_loss: 0.3924 - val_side_6_dice_coef: 0.8131 - val_side_6_jacard: 0.6979 - val_side_6_recall_1: 0.7449 - val_side_6_precision_1: 0.8893 - val_side_6_accuracy: 0.8618 - val_side_7_dice_coef: 0.8092 - val_side_7_jacard: 0.6963 - val_side_7_recall_1: 0.7321 - val_side_7_precision_1: 0.8895 - val_side_7_accuracy: 0.8574 - val_side_8_dice_coef: 0.7758 - val_side_8_jacard: 0.6559 - val_side_8_recall_1: 0.7175 - val_side_8_precision_1: 0.8426 - val_side_8_accuracy: 0.8345 - val_activation_129_dice_coef: 0.5832 - val_activation_129_jacard: 0.4219 - val_activation_129_recall_1: 0.8066 - val_activation_129_precision_1: 0.6540 - val_activation_129_accuracy: 0.7536 - val_add_53_dice_coef: 0.6076 - val_add_53_jacard: 0.4445 - val_add_53_recall_1: 0.7327 - val_add_53_precision_1: 0.8416 - val_add_53_accuracy: 0.8390\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 13/20\n",
            "64/64 [==============================] - 11s 173ms/step - loss: 1.0880 - side_6_loss: 0.0699 - side_7_loss: 0.0708 - side_8_loss: 0.1041 - activation_129_loss: 0.4535 - add_53_loss: 0.3891 - side_6_dice_coef: 0.9301 - side_6_jacard: 0.8713 - side_6_recall_1: 0.9117 - side_6_precision_1: 0.9590 - side_6_accuracy: 0.9613 - side_7_dice_coef: 0.9292 - side_7_jacard: 0.8705 - side_7_recall_1: 0.9026 - side_7_precision_1: 0.9651 - side_7_accuracy: 0.9604 - side_8_dice_coef: 0.8959 - side_8_jacard: 0.8173 - side_8_recall_1: 0.8655 - side_8_precision_1: 0.9549 - side_8_accuracy: 0.9465 - activation_129_dice_coef: 0.5465 - activation_129_jacard: 0.3835 - activation_129_recall_1: 0.8909 - activation_129_precision_1: 0.7350 - activation_129_accuracy: 0.8696 - add_53_dice_coef: 0.6109 - add_53_jacard: 0.4459 - add_53_recall_1: 0.8816 - add_53_precision_1: 0.9591 - add_53_accuracy: 0.9525 - val_loss: 1.4036 - val_side_6_loss: 0.1888 - val_side_7_loss: 0.1904 - val_side_8_loss: 0.2147 - val_activation_129_loss: 0.4171 - val_add_53_loss: 0.3919 - val_side_6_dice_coef: 0.8112 - val_side_6_jacard: 0.6952 - val_side_6_recall_1: 0.7431 - val_side_6_precision_1: 0.8842 - val_side_6_accuracy: 0.8593 - val_side_7_dice_coef: 0.8096 - val_side_7_jacard: 0.6966 - val_side_7_recall_1: 0.7304 - val_side_7_precision_1: 0.8885 - val_side_7_accuracy: 0.8565 - val_side_8_dice_coef: 0.7853 - val_side_8_jacard: 0.6681 - val_side_8_recall_1: 0.7147 - val_side_8_precision_1: 0.8615 - val_side_8_accuracy: 0.8410 - val_activation_129_dice_coef: 0.5829 - val_activation_129_jacard: 0.4212 - val_activation_129_recall_1: 0.8078 - val_activation_129_precision_1: 0.6615 - val_activation_129_accuracy: 0.7594 - val_add_53_dice_coef: 0.6081 - val_add_53_jacard: 0.4446 - val_add_53_recall_1: 0.7323 - val_add_53_precision_1: 0.8520 - val_add_53_accuracy: 0.8431\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 14/20\n",
            "64/64 [==============================] - 11s 174ms/step - loss: 1.0512 - side_6_loss: 0.0629 - side_7_loss: 0.0619 - side_8_loss: 0.0905 - activation_129_loss: 0.4505 - add_53_loss: 0.3848 - side_6_dice_coef: 0.9371 - side_6_jacard: 0.8832 - side_6_recall_1: 0.9218 - side_6_precision_1: 0.9622 - side_6_accuracy: 0.9652 - side_7_dice_coef: 0.9381 - side_7_jacard: 0.8856 - side_7_recall_1: 0.9155 - side_7_precision_1: 0.9689 - side_7_accuracy: 0.9653 - side_8_dice_coef: 0.9095 - side_8_jacard: 0.8390 - side_8_recall_1: 0.8791 - side_8_precision_1: 0.9645 - side_8_accuracy: 0.9532 - activation_129_dice_coef: 0.5495 - activation_129_jacard: 0.3865 - activation_129_recall_1: 0.8973 - activation_129_precision_1: 0.7465 - activation_129_accuracy: 0.8766 - add_53_dice_coef: 0.6152 - add_53_jacard: 0.4506 - add_53_recall_1: 0.8936 - add_53_precision_1: 0.9656 - add_53_accuracy: 0.9579 - val_loss: 1.3822 - val_side_6_loss: 0.1858 - val_side_7_loss: 0.1868 - val_side_8_loss: 0.2045 - val_activation_129_loss: 0.4156 - val_add_53_loss: 0.3890 - val_side_6_dice_coef: 0.8142 - val_side_6_jacard: 0.6994 - val_side_6_recall_1: 0.7532 - val_side_6_precision_1: 0.8776 - val_side_6_accuracy: 0.8602 - val_side_7_dice_coef: 0.8132 - val_side_7_jacard: 0.7009 - val_side_7_recall_1: 0.7389 - val_side_7_precision_1: 0.8851 - val_side_7_accuracy: 0.8581 - val_side_8_dice_coef: 0.7955 - val_side_8_jacard: 0.6810 - val_side_8_recall_1: 0.7204 - val_side_8_precision_1: 0.8725 - val_side_8_accuracy: 0.8471 - val_activation_129_dice_coef: 0.5844 - val_activation_129_jacard: 0.4226 - val_activation_129_recall_1: 0.8096 - val_activation_129_precision_1: 0.6702 - val_activation_129_accuracy: 0.7661 - val_add_53_dice_coef: 0.6110 - val_add_53_jacard: 0.4474 - val_add_53_recall_1: 0.7387 - val_add_53_precision_1: 0.8589 - val_add_53_accuracy: 0.8480\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 15/20\n",
            "64/64 [==============================] - 11s 174ms/step - loss: 1.0207 - side_6_loss: 0.0575 - side_7_loss: 0.0548 - side_8_loss: 0.0792 - activation_129_loss: 0.4477 - add_53_loss: 0.3809 - side_6_dice_coef: 0.9425 - side_6_jacard: 0.8926 - side_6_recall_1: 0.9296 - side_6_precision_1: 0.9648 - side_6_accuracy: 0.9683 - side_7_dice_coef: 0.9452 - side_7_jacard: 0.8980 - side_7_recall_1: 0.9261 - side_7_precision_1: 0.9720 - side_7_accuracy: 0.9694 - side_8_dice_coef: 0.9208 - side_8_jacard: 0.8576 - side_8_recall_1: 0.8919 - side_8_precision_1: 0.9706 - side_8_accuracy: 0.9588 - activation_129_dice_coef: 0.5523 - activation_129_jacard: 0.3892 - activation_129_recall_1: 0.9037 - activation_129_precision_1: 0.7580 - activation_129_accuracy: 0.8834 - add_53_dice_coef: 0.6191 - add_53_jacard: 0.4548 - add_53_recall_1: 0.9046 - add_53_precision_1: 0.9701 - add_53_accuracy: 0.9624 - val_loss: 1.3928 - val_side_6_loss: 0.1908 - val_side_7_loss: 0.1926 - val_side_8_loss: 0.2028 - val_activation_129_loss: 0.4155 - val_add_53_loss: 0.3905 - val_side_6_dice_coef: 0.8092 - val_side_6_jacard: 0.6931 - val_side_6_recall_1: 0.7412 - val_side_6_precision_1: 0.8843 - val_side_6_accuracy: 0.8587 - val_side_7_dice_coef: 0.8074 - val_side_7_jacard: 0.6935 - val_side_7_recall_1: 0.7241 - val_side_7_precision_1: 0.8930 - val_side_7_accuracy: 0.8559 - val_side_8_dice_coef: 0.7972 - val_side_8_jacard: 0.6840 - val_side_8_recall_1: 0.7106 - val_side_8_precision_1: 0.8879 - val_side_8_accuracy: 0.8494 - val_activation_129_dice_coef: 0.5845 - val_activation_129_jacard: 0.4228 - val_activation_129_recall_1: 0.8108 - val_activation_129_precision_1: 0.6767 - val_activation_129_accuracy: 0.7709 - val_add_53_dice_coef: 0.6095 - val_add_53_jacard: 0.4459 - val_add_53_recall_1: 0.7311 - val_add_53_precision_1: 0.8744 - val_add_53_accuracy: 0.8514\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 16/20\n",
            "64/64 [==============================] - 11s 173ms/step - loss: 0.9969 - side_6_loss: 0.0535 - side_7_loss: 0.0498 - side_8_loss: 0.0701 - activation_129_loss: 0.4452 - add_53_loss: 0.3777 - side_6_dice_coef: 0.9465 - side_6_jacard: 0.8995 - side_6_recall_1: 0.9351 - side_6_precision_1: 0.9670 - side_6_accuracy: 0.9706 - side_7_dice_coef: 0.9502 - side_7_jacard: 0.9067 - side_7_recall_1: 0.9336 - side_7_precision_1: 0.9741 - side_7_accuracy: 0.9723 - side_8_dice_coef: 0.9299 - side_8_jacard: 0.8728 - side_8_recall_1: 0.9034 - side_8_precision_1: 0.9746 - side_8_accuracy: 0.9633 - activation_129_dice_coef: 0.5548 - activation_129_jacard: 0.3917 - activation_129_recall_1: 0.9103 - activation_129_precision_1: 0.7692 - activation_129_accuracy: 0.8902 - add_53_dice_coef: 0.6223 - add_53_jacard: 0.4584 - add_53_recall_1: 0.9144 - add_53_precision_1: 0.9732 - add_53_accuracy: 0.9662 - val_loss: 1.3936 - val_side_6_loss: 0.1926 - val_side_7_loss: 0.1932 - val_side_8_loss: 0.2009 - val_activation_129_loss: 0.4156 - val_add_53_loss: 0.3907 - val_side_6_dice_coef: 0.8074 - val_side_6_jacard: 0.6903 - val_side_6_recall_1: 0.7337 - val_side_6_precision_1: 0.8848 - val_side_6_accuracy: 0.8562 - val_side_7_dice_coef: 0.8068 - val_side_7_jacard: 0.6920 - val_side_7_recall_1: 0.7188 - val_side_7_precision_1: 0.8946 - val_side_7_accuracy: 0.8546 - val_side_8_dice_coef: 0.7991 - val_side_8_jacard: 0.6853 - val_side_8_recall_1: 0.7076 - val_side_8_precision_1: 0.8912 - val_side_8_accuracy: 0.8495 - val_activation_129_dice_coef: 0.5844 - val_activation_129_jacard: 0.4223 - val_activation_129_recall_1: 0.8099 - val_activation_129_precision_1: 0.6853 - val_activation_129_accuracy: 0.7767 - val_add_53_dice_coef: 0.6093 - val_add_53_jacard: 0.4453 - val_add_53_recall_1: 0.7271 - val_add_53_precision_1: 0.8773 - val_add_53_accuracy: 0.8512\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 17/20\n",
            "64/64 [==============================] - 11s 173ms/step - loss: 0.9802 - side_6_loss: 0.0509 - side_7_loss: 0.0464 - side_8_loss: 0.0641 - activation_129_loss: 0.4430 - add_53_loss: 0.3751 - side_6_dice_coef: 0.9491 - side_6_jacard: 0.9040 - side_6_recall_1: 0.9393 - side_6_precision_1: 0.9682 - side_6_accuracy: 0.9722 - side_7_dice_coef: 0.9536 - side_7_jacard: 0.9125 - side_7_recall_1: 0.9400 - side_7_precision_1: 0.9745 - side_7_accuracy: 0.9743 - side_8_dice_coef: 0.9359 - side_8_jacard: 0.8831 - side_8_recall_1: 0.9121 - side_8_precision_1: 0.9761 - side_8_accuracy: 0.9664 - activation_129_dice_coef: 0.5570 - activation_129_jacard: 0.3940 - activation_129_recall_1: 0.9160 - activation_129_precision_1: 0.7796 - activation_129_accuracy: 0.8963 - add_53_dice_coef: 0.6249 - add_53_jacard: 0.4612 - add_53_recall_1: 0.9218 - add_53_precision_1: 0.9747 - add_53_accuracy: 0.9689 - val_loss: 1.3504 - val_side_6_loss: 0.1827 - val_side_7_loss: 0.1841 - val_side_8_loss: 0.1894 - val_activation_129_loss: 0.4101 - val_add_53_loss: 0.3835 - val_side_6_dice_coef: 0.8173 - val_side_6_jacard: 0.7050 - val_side_6_recall_1: 0.7582 - val_side_6_precision_1: 0.8806 - val_side_6_accuracy: 0.8631 - val_side_7_dice_coef: 0.8159 - val_side_7_jacard: 0.7053 - val_side_7_recall_1: 0.7452 - val_side_7_precision_1: 0.8887 - val_side_7_accuracy: 0.8617 - val_side_8_dice_coef: 0.8106 - val_side_8_jacard: 0.7008 - val_side_8_recall_1: 0.7335 - val_side_8_precision_1: 0.8895 - val_side_8_accuracy: 0.8579 - val_activation_129_dice_coef: 0.5899 - val_activation_129_jacard: 0.4286 - val_activation_129_recall_1: 0.8179 - val_activation_129_precision_1: 0.6917 - val_activation_129_accuracy: 0.7828 - val_add_53_dice_coef: 0.6165 - val_add_53_jacard: 0.4534 - val_add_53_recall_1: 0.7486 - val_add_53_precision_1: 0.8775 - val_add_53_accuracy: 0.8586\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 18/20\n",
            "64/64 [==============================] - 11s 174ms/step - loss: 0.9703 - side_6_loss: 0.0495 - side_7_loss: 0.0448 - side_8_loss: 0.0609 - activation_129_loss: 0.4411 - add_53_loss: 0.3733 - side_6_dice_coef: 0.9505 - side_6_jacard: 0.9065 - side_6_recall_1: 0.9413 - side_6_precision_1: 0.9685 - side_6_accuracy: 0.9729 - side_7_dice_coef: 0.9552 - side_7_jacard: 0.9154 - side_7_recall_1: 0.9419 - side_7_precision_1: 0.9745 - side_7_accuracy: 0.9748 - side_8_dice_coef: 0.9391 - side_8_jacard: 0.8883 - side_8_recall_1: 0.9154 - side_8_precision_1: 0.9757 - side_8_accuracy: 0.9673 - activation_129_dice_coef: 0.5589 - activation_129_jacard: 0.3958 - activation_129_recall_1: 0.9204 - activation_129_precision_1: 0.7908 - activation_129_accuracy: 0.9023 - add_53_dice_coef: 0.6267 - add_53_jacard: 0.4632 - add_53_recall_1: 0.9254 - add_53_precision_1: 0.9739 - add_53_accuracy: 0.9697 - val_loss: 1.4356 - val_side_6_loss: 0.2090 - val_side_7_loss: 0.2060 - val_side_8_loss: 0.2095 - val_activation_129_loss: 0.4165 - val_add_53_loss: 0.3940 - val_side_6_dice_coef: 0.7910 - val_side_6_jacard: 0.6693 - val_side_6_recall_1: 0.7174 - val_side_6_precision_1: 0.8694 - val_side_6_accuracy: 0.8449 - val_side_7_dice_coef: 0.7940 - val_side_7_jacard: 0.6755 - val_side_7_recall_1: 0.7079 - val_side_7_precision_1: 0.8802 - val_side_7_accuracy: 0.8457 - val_side_8_dice_coef: 0.7905 - val_side_8_jacard: 0.6732 - val_side_8_recall_1: 0.7038 - val_side_8_precision_1: 0.8756 - val_side_8_accuracy: 0.8426 - val_activation_129_dice_coef: 0.5835 - val_activation_129_jacard: 0.4214 - val_activation_129_recall_1: 0.8090 - val_activation_129_precision_1: 0.6904 - val_activation_129_accuracy: 0.7800 - val_add_53_dice_coef: 0.6060 - val_add_53_jacard: 0.4419 - val_add_53_recall_1: 0.7198 - val_add_53_precision_1: 0.8589 - val_add_53_accuracy: 0.8417\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 19/20\n",
            "64/64 [==============================] - 11s 175ms/step - loss: 0.9544 - side_6_loss: 0.0468 - side_7_loss: 0.0416 - side_8_loss: 0.0552 - activation_129_loss: 0.4392 - add_53_loss: 0.3710 - side_6_dice_coef: 0.9532 - side_6_jacard: 0.9113 - side_6_recall_1: 0.9440 - side_6_precision_1: 0.9701 - side_6_accuracy: 0.9742 - side_7_dice_coef: 0.9584 - side_7_jacard: 0.9212 - side_7_recall_1: 0.9464 - side_7_precision_1: 0.9750 - side_7_accuracy: 0.9763 - side_8_dice_coef: 0.9448 - side_8_jacard: 0.8983 - side_8_recall_1: 0.9241 - side_8_precision_1: 0.9778 - side_8_accuracy: 0.9704 - activation_129_dice_coef: 0.5608 - activation_129_jacard: 0.3977 - activation_129_recall_1: 0.9253 - activation_129_precision_1: 0.7996 - activation_129_accuracy: 0.9073 - add_53_dice_coef: 0.6290 - add_53_jacard: 0.4657 - add_53_recall_1: 0.9320 - add_53_precision_1: 0.9762 - add_53_accuracy: 0.9723 - val_loss: 1.3350 - val_side_6_loss: 0.1805 - val_side_7_loss: 0.1798 - val_side_8_loss: 0.1823 - val_activation_129_loss: 0.4095 - val_add_53_loss: 0.3823 - val_side_6_dice_coef: 0.8195 - val_side_6_jacard: 0.7073 - val_side_6_recall_1: 0.7552 - val_side_6_precision_1: 0.8872 - val_side_6_accuracy: 0.8646 - val_side_7_dice_coef: 0.8202 - val_side_7_jacard: 0.7104 - val_side_7_recall_1: 0.7443 - val_side_7_precision_1: 0.8963 - val_side_7_accuracy: 0.8642 - val_side_8_dice_coef: 0.8177 - val_side_8_jacard: 0.7090 - val_side_8_recall_1: 0.7389 - val_side_8_precision_1: 0.8954 - val_side_8_accuracy: 0.8620 - val_activation_129_dice_coef: 0.5905 - val_activation_129_jacard: 0.4291 - val_activation_129_recall_1: 0.8209 - val_activation_129_precision_1: 0.7029 - val_activation_129_accuracy: 0.7910 - val_add_53_dice_coef: 0.6177 - val_add_53_jacard: 0.4545 - val_add_53_recall_1: 0.7512 - val_add_53_precision_1: 0.8832 - val_add_53_accuracy: 0.8617\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n",
            "Epoch 20/20\n",
            "64/64 [==============================] - 11s 175ms/step - loss: 0.9368 - side_6_loss: 0.0438 - side_7_loss: 0.0374 - side_8_loss: 0.0494 - activation_129_loss: 0.4371 - add_53_loss: 0.3684 - side_6_dice_coef: 0.9562 - side_6_jacard: 0.9166 - side_6_recall_1: 0.9496 - side_6_precision_1: 0.9700 - side_6_accuracy: 0.9758 - side_7_dice_coef: 0.9626 - side_7_jacard: 0.9287 - side_7_recall_1: 0.9538 - side_7_precision_1: 0.9768 - side_7_accuracy: 0.9791 - side_8_dice_coef: 0.9506 - side_8_jacard: 0.9082 - side_8_recall_1: 0.9335 - side_8_precision_1: 0.9795 - side_8_accuracy: 0.9738 - activation_129_dice_coef: 0.5629 - activation_129_jacard: 0.3998 - activation_129_recall_1: 0.9311 - activation_129_precision_1: 0.8108 - activation_129_accuracy: 0.9136 - add_53_dice_coef: 0.6316 - add_53_jacard: 0.4687 - add_53_recall_1: 0.9398 - add_53_precision_1: 0.9775 - add_53_accuracy: 0.9751 - val_loss: 1.3581 - val_side_6_loss: 0.1888 - val_side_7_loss: 0.1860 - val_side_8_loss: 0.1875 - val_activation_129_loss: 0.4106 - val_add_53_loss: 0.3846 - val_side_6_dice_coef: 0.8112 - val_side_6_jacard: 0.6962 - val_side_6_recall_1: 0.7437 - val_side_6_precision_1: 0.8812 - val_side_6_accuracy: 0.8583 - val_side_7_dice_coef: 0.8140 - val_side_7_jacard: 0.7023 - val_side_7_recall_1: 0.7340 - val_side_7_precision_1: 0.8923 - val_side_7_accuracy: 0.8591 - val_side_8_dice_coef: 0.8125 - val_side_8_jacard: 0.7018 - val_side_8_recall_1: 0.7313 - val_side_8_precision_1: 0.8907 - val_side_8_accuracy: 0.8576 - val_activation_129_dice_coef: 0.5894 - val_activation_129_jacard: 0.4277 - val_activation_129_recall_1: 0.8181 - val_activation_129_precision_1: 0.7110 - val_activation_129_accuracy: 0.7956 - val_add_53_dice_coef: 0.6154 - val_add_53_jacard: 0.4517 - val_add_53_recall_1: 0.7430 - val_add_53_precision_1: 0.8779 - val_add_53_accuracy: 0.8568\n",
            "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYLuEALcKF5W"
      },
      "source": [
        "import pandas as pd\n",
        "# convert the history.history dict to a pandas DataFrame:\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "\n",
        "\n",
        "\n",
        "# save to json:\n",
        "hist_json_file = 'history_skin_drrmsan.json'\n",
        "# with open(hist_json_file, 'a') as out:\n",
        "#     out.write(hist_df.to_json())\n",
        "#     out.write(\",\")\n",
        "#     out.close()\n",
        "\n",
        "with open(hist_json_file, mode='w') as f:\n",
        "    hist_df.to_json(f)\n",
        "\n",
        "# or save to csv:\n",
        "hist_csv_file = 'history_skin_drrmsan.csv'\n",
        "# with open(hist_csv_file, 'a') as out:\n",
        "#     out.write(str(hist_df.to_csv()))\n",
        "#     out.write(\",\")\n",
        "#     out.close()\n",
        "\n",
        "\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoIwEPZpKMGr"
      },
      "source": [
        "model.save_weights(\"skin_drrmsan_150e.h5\")\n",
        "model.save(\"skin_drrmsan_with_weight_150e.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B_q_CCwKOZC"
      },
      "source": [
        "# Run this module only while loading the pre-trained model.\n",
        "model = load_model('skin_drrmsan_with_weight_150e.h5',custom_objects={'dice_loss': dice_loss,'dice_coef':dice_coef, 'jacard':jacard})\n",
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lkw9BPx1KRXc"
      },
      "source": [
        "\n",
        "jaccard_index_list = []\n",
        "dice_coeff_list = []\n",
        "\n",
        "def evaluateModel(model, X_test, Y_test, batchSize):  \n",
        "    \n",
        "    try:\n",
        "        os.makedirs('results')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "\n",
        "    yp = model.predict(x=X_test, batch_size=batchSize, verbose=1)\n",
        "    \n",
        "\n",
        "    yp = np.round(yp,0)\n",
        "    #print(yp.shape)\n",
        "    yp = yp[4]\n",
        "    #print(yp1.shape)\n",
        "\n",
        "    for i in range(10):\n",
        "\n",
        "        plt.figure(figsize=(20,10))\n",
        "        plt.subplot(1,3,1)\n",
        "        plt.imshow(X_test[i])\n",
        "        plt.title('Input')\n",
        "        plt.subplot(1,3,2)\n",
        "        plt.imshow(Y_test[i].reshape(Y_test[i].shape[0],Y_test[i].shape[1]))\n",
        "        plt.title('Ground Truth')\n",
        "        plt.subplot(1,3,3)\n",
        "        plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]))\n",
        "        plt.title('Prediction')\n",
        "\n",
        "        intersection = yp[i].ravel() * Y_test[i].ravel()\n",
        "        union = yp[i].ravel() + Y_test[i].ravel() - intersection\n",
        "\n",
        "        jacard = (np.sum(intersection)/np.sum(union))\n",
        "        plt.suptitle('Jacard Index'+ str(np.sum(intersection)) +'/'+ str(np.sum(union)) +'='+str(jacard))\n",
        "\n",
        "        plt.savefig('results/'+str(i)+'.png',format='png')\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "    jacard = 0\n",
        "    dice = 0\n",
        "\n",
        "\n",
        "    for i in range(len(Y_test)):\n",
        "        yp_2 = yp[i].ravel()\n",
        "        y2 = Y_test[i].ravel()\n",
        "\n",
        "        intersection = yp_2 * y2\n",
        "        union = yp_2 + y2 - intersection\n",
        "\n",
        "        jacard += (np.sum(intersection)/np.sum(union))\n",
        "\n",
        "        dice += (2. * np.sum(intersection) ) / (np.sum(yp_2) + np.sum(y2))\n",
        "\n",
        "\n",
        "    jacard /= len(Y_test)\n",
        "    dice /= len(Y_test)\n",
        "\n",
        "\n",
        "\n",
        "    print('Jacard Index : '+str(jacard))\n",
        "    print('Dice Coefficient : '+str(dice))\n",
        "    with open(\"Output.txt\", \"w\") as text_file:\n",
        "        text_file.write(\"Jacard : {} Dice Coef : {} \".format(str(jacard), str(dice)))\n",
        "\n",
        "    jaccard_index_list.append(jacard)\n",
        "    dice_coeff_list.append(dice)\n",
        "    fp = open('models/log_drrmsan_skinleison.txt','a')\n",
        "    fp.write(str(jacard)+'\\n')\n",
        "    fp.close()\n",
        "\n",
        "    fp = open('models/best_drrmsan_skinleison.txt','r')\n",
        "    best = fp.read()\n",
        "    fp.close()\n",
        "\n",
        "    if(jacard>float(best)):\n",
        "        print('***********************************************')\n",
        "        print('Jacard Index improved from '+str(best)+' to '+str(jacard))\n",
        "        print('***********************************************')\n",
        "        fp = open('models/best_UNet_skinleison.txt','w')\n",
        "        fp.write(str(jacard))\n",
        "        fp.close()\n",
        "\n",
        "        #saveModel(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U9Fc90XKWi1",
        "outputId": "b754ad02-31af-40be-f5b2-2c19d3c1162b"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "X_test = []\n",
        "Y_test = []\n",
        "\n",
        "for img_fl, img_msk in tqdm(zip(x_test, y_test)):\n",
        "    img = cv2.imread('{}'.format(img_fl), cv2.IMREAD_COLOR)\n",
        "    X_test.append(img)\n",
        "    #img_msk = \"../trainy/Y_img_\"+str(img_fl.split('.')[2]).split('_')[-1]+\".bmp\"\n",
        "    msk = cv2.imread('{}'.format(img_msk), cv2.IMREAD_GRAYSCALE)\n",
        "    Y_test.append(msk)#resized_msk)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40it [00:00, 1781.70it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNby5NPxKWfx"
      },
      "source": [
        "\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "Y_test = np.array(Y_test)\n",
        "\n",
        "Y_test = Y_test.reshape((Y_test.shape[0],Y_test.shape[1],Y_test.shape[2],1))\n",
        "\n",
        "X_test = X_test / 255\n",
        "Y_test = Y_test / 255\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy0XJjLQKUMy",
        "outputId": "49a9ffe4-407c-412c-ffd7-26c011737683"
      },
      "source": [
        "#Y_test = np.round(Y_test,0)\t\n",
        "\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40, 192, 256, 3)\n",
            "(40, 192, 256, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq-CIyI9KphE"
      },
      "source": [
        "try:\n",
        "    os.makedirs('models')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "fp = open('models/log_drrmsan_skinleison.txt','w')\n",
        "fp.close()\n",
        "fp = open('models/best_drrmsan_skinleison.txt','w')\n",
        "fp.write('-1.0')\n",
        "fp.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU8qeD4wKpeA",
        "outputId": "347fbedc-8f61-42fc-a040-8b8db0edc260"
      },
      "source": [
        "evaluateModel(model, X_test, Y_test, BATCH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 2s 39ms/step\n",
            "Jacard Index : 0.7398375273277367\n",
            "Dice Coefficient : 0.8339396318727589\n",
            "***********************************************\n",
            "Jacard Index improved from -1.0 to 0.7398375273277367\n",
            "***********************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FCxSrrVKpbB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHXawdmNKpYq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}